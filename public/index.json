[{"content":"An autoencoder is a type of artificial neural network that learns to create efficient codings, or representations, of unlabeled data, making it useful for unsupervised learning. Autoencoders can be used for tasks like reducing the number of dimensions in data, extracting important features, and removing noise. They\u0026rsquo;re also important for building semi-supervised learning models and generative models. The concept of autoencoders has inspired many advanced models.\nIn this blog post, we\u0026rsquo;ll start with a simple introduction to autoencoders. Then, we\u0026rsquo;ll show how to build an autoencoder using a fully-connected neural network. We\u0026rsquo;ll explain what sparsity constraints are and how to add them to neural networks. After that, we\u0026rsquo;ll go over how to build autoencoders with convolutional neural networks. Finally, we\u0026rsquo;ll talk about some common uses for autoencoders.\nYou can find all the source code and tutorial scripts mentioned in this blog post in my GitHub repository (URL: https://github.com/JianZhongDev/AutoencoderPyTorch/tree/main ).\nAutoencoder Network Redundancy of Data Representation The key idea behind autoencoders is to reduce redundancy in data representation. Often, data is represented in a way that isn\u0026rsquo;t very efficient, leading to higher dimensions than necessary. This means many parts of the data are redundant. For example, the MNIST dataset contains 28x28 pixel images of handwritten digits from 0 to 9. Ideally, we only need one variable to represent these digits, but the image representation uses 784 (28x28) grayscale values.\nAutoencoders work by compressing the features as the neural network processes the data and then reconstructing the original data from this compressed form. This process helps the network learn a more efficient way to represent the input data.\nTypical Structure of an Autoencoder Network An autoencoder network typically has two parts: an encoder and a decoder. The encoder compresses the input data into a smaller, lower-dimensional form. The decoder then takes this smaller form and reconstructs the original input data. This smaller form, created by the encoder, is often called the latent space or the \u0026ldquo;bottleneck.\u0026rdquo; The latent space usually has fewer dimensions than the original input data.\nArchitecture of autoencoder. (image credit: Jian Zhong)\nFully-Connected Autoencoder Implementing an autoencoder using a fully connected network is straightforward. For the encoder, we use a fully connected network where the number of neurons decreases with each layer. For the decoder, we do the opposite, using a fully connected network where the number of neurons increases with each layer. This creates a \u0026ldquo;bottleneck\u0026rdquo; structure in the middle of the network.\nHere is a code example demonstrating how to implement the encoder and decoder of a simple autoencoder network using fully-connected neural networks.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 from .Layers import StackedLayers ## fully connected network with only fully connected layers class SimpleFCNetwork(nn.Module): def __init__( self, layer_descriptors = [], ): assert isinstance(layer_descriptors, list) super().__init__() self.network = StackedLayers.VGGStackedLinear(layer_descriptors) def forward(self, x): y = self.network(x) return y ## create models using the above Module nof_features = 28 * 28 code_dim = 64 ## create encoder model encoder_layer_descriptors = [ {\u0026#34;nof_layers\u0026#34;: 1, \u0026#34;in_features\u0026#34;: nof_features, \u0026#34;out_features\u0026#34;: code_dim, \u0026#34;activation\u0026#34;: torch.nn.LeakyReLU}, ] encoder = SimpleFCNetwork( layer_descriptors = encoder_layer_descriptors ) print(\u0026#34;Encoder:\u0026#34;) print(encoder) print(\u0026#34;\\n\u0026#34;) ## create decoder model decoder_layer_descriptors = [ {\u0026#34;nof_layers\u0026#34;: 1, \u0026#34;in_features\u0026#34;: code_dim, \u0026#34;out_features\u0026#34;: nof_features, \u0026#34;activation\u0026#34;: torch.nn.LeakyReLU}, ] decoder = SimpleFCNetwork( layer_descriptors = decoder_layer_descriptors ) print(\u0026#34;Decoder:\u0026#34;) print(decoder) The VGGStackedLinear module creates several fully-connected networks based on the input layer descriptors. For a detailed explanation, please refer to my blog post on building and training VGG network with PyTorch.\nHere\u0026rsquo;s how the architecture of the encoder and decoder defined above looks:\nclick to expand simple fully-connected autoencoder printout\rEncoder: SimpleFCNetwork( (network): VGGStackedLinear( (network): Sequential( (0): Linear(in_features=784, out_features=64, bias=True) (1): LeakyReLU(negative_slope=0.01) ) ) ) Decoder: SimpleFCNetwork( (network): VGGStackedLinear( (network): Sequential( (0): Linear(in_features=64, out_features=784, bias=True) (1): LeakyReLU(negative_slope=0.01) ) ) ) After training the fully-connected network, here are the results for an example data input/output, the latent representation of data in a batch of 512 samples, and the learned feature dictionary:\nTraining results of a simple fully-connected autoencoder (encoder: 784-64, decoder 64-784). a, example data input/output. b, latent representation of data in a batch of 512 samples. c, the learned (decoder) feature dictionary. (image credit: Jian Zhong)\nWithout additional constraints, each sample typically contains numerous non-zero latent features of similar amplitudes, and the learned feature dictionary tends to be highly localized.\nFor a comprehensive understanding of how the above network was implemented and trained, please refer to the TrainSimpleFCAutoencoder Jupyter notebook in my GitHub repository.\nSparsity and Sparse Autoencoder In machine learning, sparsity suggests that in many high-dimensional datasets, only a small number of features or variables are meaningful or non-zero for each observation. In an optimal representation space, many features either have zero values or values that are negligible.\nIn the context of autoencoders, a sparse latent representation of the data is often preferred. This sparse representation can be achieved by incorporating sparse constraints into the network. Adding these constraints helps the autoencoder focus on learning more meaningful features.\nHard Sparsity in Latent Representation Implementing hard sparsity in the latent space involves adding a sparsity layer at the end of the encoder network along the feature dimension. To create a hard sparsity layer, we specify a number k of features to retain in the latent space. During the forward pass, this layer keeps only the top k largest features of the encoded representation for each sample, setting the rest to 0. During backward propagation, the hard sparsity layer only propagates gradients for these top k features.\nHere\u0026rsquo;s how the hard sparsity layer is implemented:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # hard sparsity function to select the largest k features for each sample in the batch input data # NOTE: this function works on 1d feature space class FeatureTopKFunction(torch.autograd.Function): @staticmethod def forward(ctx, x, k): assert len(x.size()) == 2 src_data_detach = x.detach() # create mask indicating the top k features for each sample within the feature space topk_mask = torch.zeros_like(x, dtype = bool, requires_grad = False) _, indices = src_data_detach.topk(k, dim = -1) for i_batch in range(x.size(0)): topk_mask[i_batch, indices[i_batch,:]] = True # save mask for backward propagation ctx.save_for_backward(topk_mask) # only propagate largest k features of each sample y = torch.zeros_like(x) y[topk_mask] = x[topk_mask] return y @staticmethod def backward(ctx, grad_output): topk_mask = ctx.saved_tensors[0] # only propagate gradient for largest k features of each sample grad_input = torch.zeros_like(grad_output, requires_grad = True) grad_input[topk_mask] = grad_output[topk_mask] return grad_input, None # hard sparsity layer class TopKSparsity(nn.Module): def __init__(self, topk = 1): super().__init__() self.topk = topk def __repr__(self): return self.__class__.__name__ + f\u0026#34;(topk = {self.topk})\u0026#34; def forward(self, x): y = FeatureTopKFunction.apply(x, self.topk) return y First, we created our own operation FeatureTopKFunction for hard sparsity and defined its functions for both forward and backward passes. During the forward pass, a mask is generated to identify the top k features of each input sample, which is then stored for later use in the backward pass. This mask ensures that only the top k values are kept, while the rest are set to zero for both value and gradient calculations. In the hard sparsity layer, we specify the number k and incorporate the hard sparsity operation into the forward() method.\nTo implement hard sparsity in an autoencoder, simply add a hard sparsity layer at the end of the encoder network as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # fully connected network with sparsity layer class SimpleSparseFCNetwork(nn.Module): def __init__( self, layer_descriptors = [], feature_sparsity_topk = None, ): assert isinstance(layer_descriptors, list) super().__init__() self.network = nn.Identity() network_layers = [] # add stacked fully connected layers network_layers.append(StackedLayers.VGGStackedLinear(layer_descriptors)) # add top k sparsity along the feature dimension if feature_sparsity_topk is not None : network_layers.append(SparseLayers.TopKSparsity(feature_sparsity_topk)) if len(network_layers) \u0026gt; 0: self.network = nn.Sequential(*network_layers) def forward(self, x): y = self.network(x) return y After training the fully-connected network with these hard sparsity constraints, here are the outcomes for a sample data input/output, the latent representations of data in a batch of 512 samples, and the learned feature dictionary:\nTraining results of a simple fully-connected autoencoder with hard sparsity (encoder: 784-64-sparsity, decoder 64-784). a-c, results of autoencoder trained with top 16 sparsity. d-f, results of autoencoder trained with top 5 sparsity. a,d, example data input/output. b,e, latent representation of data in a batch of 512 samples. c,f, the learned (decoder) feature dictionary. (image credit: Jian Zhong)\nFrom the results above, we observe that increasing the required sparsity with hard constraints reduces the number of non-zero features in the latent space. This encourages the network to learn more global features.\nFor a detailed understanding of how this network was implemented and trained, please refer to the TrainSimpleSparseFCAutoencoder Jupyter notebook in my GitHub repository.\nSoft Sparsity in Latent Representation We can also encourage sparsity in the encoded features of the latent space by applying a soft constraint. This involves adding an additional penalty term to the loss function. The modified loss function with the sparsity penalty appears as follows:\n$$ H_{\\theta}(pred,gt) = J_{\\theta}(pred,gt) + \\lambda \\cdot L_{\\theta}(code) $$\nHere, \\(\\theta, pred, gt\\) represents the parameters of the autoencoder network, the output prediction of autoencoder, and the ground truth data, respectively. \\(H_{\\theta}(pred,gt)\\) ​ is the loss function with sparsity constraints, where \\(J_{\\theta}(pred,gt)\\) is the original loss function, which measures the difference between the network prediction and ground truth. \\(L_{\\theta}(pred,gt)\\) ​ denotes the penalty term for enforcing sparsity. The parameter \\(\\lambda\\) controls the strength of this penalty.\nThe L1 loss of the encoded features is commonly used as a sparsity loss. This loss function is readily available in PyTorch.\nAnother approach to implementing sparsity loss is through a penalty based on KL divergence. The penalty term for this KL divergence-based sparsity can be defined as follows:\n$$ L_{\\theta} = \\frac{1}{s} \\sum^{s}_{j=1} KL(\\rho||\\hat{\\rho_j}) $$\nHere, ​ \\(s\\) represents the number of features in the encoded representation, which corresponds to the dimension of the latent space. ​ \\(j\\) is index for the features in the latent space. \\(KL(\\rho||\\hat{\\rho_j})\\) is calculated as follows:\n$$ KL(\\rho||\\hat{\\rho_j}) = \\rho \\cdot log(\\frac{\\rho}{\\hat{\\rho}_j}) + (1 - \\rho) \\cdot log(\\frac{1-\\rho}{1-\\hat{\\rho}_j}) $$\nHere, \\(\\rho\\) is a sparsity parameter, typically a small value close to zero that is provided during training. \\(\\hat{\\rho}_j\\) ​ is computed from the j-th latent features of the samples within the mini-batch as follows:\n$$ \\hat{\\rho_{j}} = \\frac{1}{m} \\sum^{m}_{i=1} l_i $$\nHere, \\(m\\) denotes the batch size. \\(j\\) indexes the features within the latent space. \\(i\\) indexes the samples within the minibatch. \\(l\\) represents each individual feature within the latent space.\nNote that for the KL divergence expression, the values of \\(\\rho\\) and \\(\\hat{\\rho}_j\\) ​ must fall within the range \\((0,1)\\) . This range should be ensured by using suitable activation functions (such as sigmoid) for the output layer of the encoder, or by appropriately normalizing the latent space features before computing the sparsity loss.\nBelow is the PyTorch code implementation for the KL-divergence based sparsity loss:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Kullback-Leibler divergence formula def kullback_leibler_divergence( rho, rho_hat ): return rho * torch.log(rho/rho_hat) + (1 - rho)*torch.log((1 - rho)/(1 - rho_hat)) # nn.Module of sparsity loss function class KullbackLeiblerDivergenceLoss(nn.Module): def __init__(self, rho = 0.05): assert rho \u0026gt; 0 and rho \u0026lt; 1 super().__init__() self.rho = rho def forward(self, x): rho_hat = torch.mean(x, dim = 0) kl = torch.mean(kullback_leibler_divergence(self.rho, rho_hat)) return kl After training a basic fully-connected autoencoder model with soft sparsity constraints, the results are as follows:\nTraining results of a simple fully-connected autoencoder with soft sparsity (encoder: 784-64, decoder 64-784, KL-divergence soft sparsity loss \\(\\rho = 0.05\\) ). a-c, results of autoencoder trained with \\(\\lambda = 10^{-2}\\) . d-f, results of autoencoder trained with \\(\\lambda = 10^{-1}\\) . a,d, example data input/output. b,e, latent representation of data in a batch of 512 samples. c,f, the learned (decoder) feature dictionary. (image credit: Jian Zhong)\nIncreasing the strength of the sparsity penalty decreases the number of non-zero features in the latent space.\nFor a comprehensive understanding of how this network was implemented and trained, please refer to the TrainSimpleFCAutoencoderWithSparseLoss Jupyter notebook in my GitHub repository.\nLifetime (Winner-Takes-All) Sparsity Unlike conventional sparsity constraints that aim to increase sparsity within each individual sample, lifetime sparsity enforces sparsity across minibatch samples for each feature. Here\u0026rsquo;s how lifetime sparsity can be implemented:\nDuring training, in the forward propagation phase, for each feature in the latent space, we retain the top k largest values across all minibatch samples and set the remaining values of that feature to zero. During backward propagation, gradients are propagated only for these k non-zero values.\nDuring testing, we disable the lifetime sparsity constraints, allowing the encoder network to output the final representation of the input. The implementation of lifetime sparsity operations is as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # lifetime sparsity functon to select the largest k samples for each feature # NOTE: this function works on 1d feature space class LifetimeTopKFunction(torch.autograd.Function): @staticmethod def forward(ctx, x, k): assert len(x.size()) == 2 k = min(k, x.size(0)) src_data_detach = x.detach() # create mask indicating the top k samples for each feature along the batch dimension topk_mask = torch.zeros_like(x, dtype = bool, requires_grad = False) _, indices = src_data_detach.topk(k, dim = 0) for i_feature in range(x.size(-1)): topk_mask[indices[:,i_feature],i_feature] = True # save mask indicationg the top k samples for each feature for back propagation ctx.save_for_backward(topk_mask) # only propagate largest k samples for each feature y = torch.zeros_like(x) y[topk_mask] = x[topk_mask] return y @staticmethod def backward(ctx, grad_output): topk_mask = ctx.saved_tensors[0] # only propagate gradient for largest k samples for each feature grad_input = torch.zeros_like(grad_output, requires_grad = True) grad_input[topk_mask] = grad_output[topk_mask] return grad_input, None In the forward pass, we create a mask that identifies the top k values across the minibatch dimension for each feature in the latent space. This mask is saved for use during the backward pass. During both forward and backward passes, this mask ensures that only the top k values of each feature are retained, while the rest are set to zero.\nWith these lifetime sparsity operations, we can implement a neural network layer that enforces lifetime sparsity as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # lifetime sparsity layer class LifetimeTopkSparsity(nn.Module): def __init__(self, topk = 5): super().__init__() self.topk = topk def __repr__(self): return self.__class__.__name__ + f\u0026#34;(topk = {self.topk})\u0026#34; def forward(self, x): y = None if self.training: # only apply lifetime sparsity during training y = LifetimeTopKFunction.apply(x, self.topk) else: y = x return y In the lifetime sparsity layer, we store the k values within the network object. During training, this layer implements lifetime sparsity operations. During testing, the layer simply passes the input directly to the output.\nTo implement lifetime sparsity in an autoencoder, we add the lifetime sparsity layer at the end of the encoder network as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # fully connected network with sparsity layer class SimpleSparseFCNetwork(nn.Module): def __init__( self, layer_descriptors = [], lifetime_sparsity_topk = None, ): assert isinstance(layer_descriptors, list) super().__init__() self.network = nn.Identity() network_layers = [] # add stacked fully connected layers network_layers.append(StackedLayers.VGGStackedLinear(layer_descriptors)) # add top k sparsity along the sample(batch) dimension if lifetime_sparsity_topk is not None: network_layers.append(SparseLayers.LifetimeTopkSparsity(lifetime_sparsity_topk)) if len(network_layers) \u0026gt; 0: self.network = nn.Sequential(*network_layers) def forward(self, x): y = self.network(x) return y After training a simple fully-connected autoencoder model with a lifetime sparsity layer, the results are as follows:\nTraining results of a simple fully-connected autoencoder with life time sparsity (encoder: 784-64-sparsity, decoder 64-784). a-c, results of autoencoder trained with top 25% sparsity. d-f, results of autoencoder trained with top 5% sparsity. a,d, example data input/output. b,e, latent representation of data in a batch of 512 samples. c,f, the learned (decoder) feature dictionary. (image credit: Jian Zhong)\nIncreasing the strength of the lifetime sparsity constraint reduces the number of non-zero features in the latent space. This encourages the network to learn more global features.\nFor detailed insights into how this network was implemented and trained, please refer to the TrainSimpleSparseFCAutoencoder Jupyter notebook in my GitHub repository.\nConvolutional Autoencoder For image data, the encoder network can also be implemented using a convolutional network, where the feature dimensions decrease as the encoder becomes deeper. Max pooling layers can be added to further reduce feature dimensions and induce sparsity in the encoded features. Here\u0026rsquo;s an example of a convolutional encoder network:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # simple convolutional encoder = stacked convolutional network + maxpooling class SimpleCovEncoder(nn.Module): def __init__( self, convlayer_descriptors = [], maxpoollayer_descriptor = {}, ): assert(isinstance(convlayer_descriptors, list)) assert(isinstance(maxpoollayer_descriptor, dict)) super().__init__() self.network = nn.Identity() network_layers = [] # append stacked convolution layer network_layers.append(StackedLayers.VGGStacked2DConv(convlayer_descriptors)) # append maxpooling layer network_layers.append( nn.MaxPool2d( kernel_size = maxpoollayer_descriptor.get(\u0026#34;kernel_size\u0026#34;, 2), stride = maxpoollayer_descriptor.get(\u0026#34;stride\u0026#34;, 2), padding = maxpoollayer_descriptor.get(\u0026#34;padding\u0026#34;, 0), dilation = maxpoollayer_descriptor.get(\u0026#34;dilation\u0026#34;, 1), ) ) # flatten output feature space network_layers.append(nn.Flatten(start_dim = 1, end_dim = -1)) if len(network_layers) \u0026gt; 0: self.network = nn.Sequential(*network_layers) def forward(self, x): y = self.network(x) return y ## create encoder model encoder_convlayer_descriptors = [ { \u0026#34;nof_layers\u0026#34;: 4, \u0026#34;in_channels\u0026#34;: 1, \u0026#34;out_channels\u0026#34;: 8, \u0026#34;kernel_size\u0026#34;: 6, \u0026#34;stride\u0026#34;: 1, \u0026#34;padding\u0026#34;: 0, \u0026#34;activation\u0026#34;: torch.nn.LeakyReLU } ] encoder_maxpoollayer_descriptor = { \u0026#34;kernel_size\u0026#34;: 2, \u0026#34;stride\u0026#34;: 2, } encoder = ConvAutoencoder.SimpleCovEncoder( encoder_convlayer_descriptors, encoder_maxpoollayer_descriptor, ) print(\u0026#34;Encoder:\u0026#34;) print(encoder) The VGGStacked2DConv module generates multiple convolutional networks based on the input layer descriptors. For a detailed explanation, please refer to my blog post on building and training VGG network with PyTorch.\nHere\u0026rsquo;s a visualization of the architecture of the encoder and decoder described above:\nclick to expand convolutional encoder printout\rEncoder: SimpleCovEncoder( (network): Sequential( (0): VGGStacked2DConv( (network): Sequential( (0): Conv2d(1, 8, kernel_size=(6, 6), stride=(1, 1)) (1): LeakyReLU(negative_slope=0.01) (2): Conv2d(8, 8, kernel_size=(6, 6), stride=(1, 1)) (3): LeakyReLU(negative_slope=0.01) (4): Conv2d(8, 8, kernel_size=(6, 6), stride=(1, 1)) (5): LeakyReLU(negative_slope=0.01) (6): Conv2d(8, 8, kernel_size=(6, 6), stride=(1, 1)) (7): LeakyReLU(negative_slope=0.01) ) ) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): Flatten(start_dim=1, end_dim=-1) ) ) After training the fully-connected network, here are the results for a sample data input/output, the latent representation of data in a batch of 512 samples, and the learned feature dictionary:\nTraining results of a simple autoencoder with convolutional encoder and fully-connected decoder (encoder: Conv6x6-Conv6x6-Conv6x6-Conv6x6-MaxPool2x2, decoder 128-784). a, example data input/output. b, latent representation of data in a batch of 512 samples. c, the learned (decoder) feature dictionary. (image credit: Jian Zhong)\nFor a detailed understanding of how this network was implemented and trained, please see the TrainSimpleConvAutoencoder Jupyter notebook in my GitHub repository.\nTraining and Validation During training, the optimal encoding of input data is generally unknown. In an autoencoder network, the encoder and decoder are trained concurrently. The encoder processes input data to generate compressed representations, while during testing, the decoder reconstructs the input from these representations. The objective of training is to minimize the discrepancy between the decoder\u0026rsquo;s output and the original input data. Typically, Mean Squared Error (MSE) loss is selected as the optimization loss function for this purpose.\nTraining Dataset When training an autoencoder with image datasets, both the input data and the ground truth are images. Depending on the application of the autoencoder, the input data and ground truth images may not necessarily be identical.\nIn this blog post, we will use the MNIST dataset for our demonstration. In PyTorch, the MNIST dataset provides handwritten digit images as input data and the corresponding digits as ground truth. To train the autoencoder with MNIST and potentially apply various transformations to both input and ground truth images, we implement the following dataset class. This class converts conventional supervised learning datasets into datasets suitable for autoencoder training.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # convert supervised data to autoencoder data def supdata_to_autoencoderdata( supdata, feature_transform = None, target_transform = None, ): src_feature = supdata[0] #extract feature # NOTE: the usuer of this function is responsible for necessary data duplication feature = src_feature if feature_transform: feature = feature_transform(feature) target = src_feature if target_transform: target = target_transform(target) return feature, target # dataset class of autoencoder using existing supervised learning dataset class AutoencoderDataset(torch.utils.data.Dataset): def __init__( self, src_supdataset, feature_transform = None, target_transform = None, ): self.dataset = src_supdataset self.feature_transform = feature_transform self.target_transform = target_transform def __len__(self): return len(self.dataset) def __getitem__(self, idx): src_data = self.dataset[idx] feature, target = supdata_to_autoencoderdata( src_data, self.feature_transform, self.target_transform, ) return feature, target Training and Validation Process The training process for one epoch is implemented as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 # train encoder and decoder for one epoch def train_one_epoch( encoder_model, decoder_model, train_loader, data_loss_func, optimizer, code_loss_rate = 0, code_loss_func = None, device = None, ): tot_loss = 0.0 avg_loss = 0.0 tot_nof_batch = 0 encoder_model.train(True) decoder_model.train(True) for i_batch, data in enumerate(train_loader): inputs, targets = data if device: inputs = inputs.to(device) targets = targets.to(device) optimizer.zero_grad() cur_codes = encoder_model(inputs) # encode input data into codes in latent space cur_preds = decoder_model(cur_codes) # reconstruct input image data_loss = data_loss_func(cur_preds, targets) # loss for contraints in the latent space code_loss = 0 if code_loss_func: code_loss = code_loss_func(cur_codes) loss = data_loss + code_loss_rate * code_loss loss.backward() optimizer.step() tot_loss += loss.item() tot_nof_batch += 1 if i_batch % 100 == 0: print(f\u0026#34;batch {i_batch} loss: {tot_loss/tot_nof_batch: \u0026gt;8f}\u0026#34;) avg_loss = tot_loss/tot_nof_batch print(f\u0026#34;Train: Avg loss: {avg_loss:\u0026gt;8f}\u0026#34;) return avg_loss Mean Squared Error (MSE) loss is typically used as the loss function during training. For sparse autoencoder training, where a sparsity penalty needs to be incorporated into the loss function, the train for one epoch function accepts inputs for the sparsity penalty and its weight.\nThe validation process for one epoch can be implemented as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # validate encoder and decoder for one epoch def validate_one_epoch( encoder_model, decoder_model, validate_loader, loss_func, device = True, ): tot_loss = 0.0 avg_loss = 0.0 tot_nof_batch = len(validate_loader) tot_samples = len(validate_loader.dataset) encoder_model.eval() decoder_model.eval() with torch.no_grad(): for i_batch, data in enumerate(validate_loader): inputs, targets = data if device: inputs = inputs.to(device) targets = targets.to(device) cur_codes = encoder_model(inputs) # encode input data into codes in latent space cur_preds = decoder_model(cur_codes) # reconstruct input image loss = loss_func(cur_preds, targets) tot_loss += loss.item() avg_loss = tot_loss/tot_nof_batch print(f\u0026#34;Validate: Avg loss: {avg_loss: \u0026gt; 8f}\u0026#34;) return avg_loss Tying and Untying Layer Weights When training a fully-connected network with symmetrical encoder and decoder structures, it is recommended to initially share the same weight matrix between corresponding layers of the encoder and decoder. Later, for fine-tuning, the weight matrices are separated. This operation is referred to as \u0026rsquo;tying the weights\u0026rsquo; when they are shared, and \u0026lsquo;untying the weights\u0026rsquo; when they are separated.\nIn PyTorch, we can implement the operations to tie and untie the encoder-decoder matrices as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 # create tied linear layer class WeightTiedLinear(nn.Module): def __init__( self, src_linear: nn.Linear, tie_to_linear: nn.Linear ): super().__init__() assert src_linear.weight.size() == tie_to_linear.weight.t().size() self.tie_to_linear = tie_to_linear self.bias = nn.Parameter(src_linear.bias.clone()) # use tie_to_linear layer weigth for foward propagation def forward(self, input): return F.linear(input, self.tie_to_linear.weight.t(), self.bias) # return weight of tied linear layer @property def weight(self): return self.tie_to_linear.weight.t() # tie weights for symmetrical fully-connected auto encoder network. def tie_weight_sym_fc_autoencoder( encoder_model: nn.Module, decoder_model: nn.Module, skip_no_grad_layer = False, ): # get all the fully connected layers encoder_fc_layers = [{\u0026#34;indexing_str\u0026#34;: cur_layerstr, \u0026#34;module\u0026#34;: cur_module} for cur_layerstr, cur_module in encoder_model.named_modules() if isinstance(cur_module, nn.Linear)] decoder_fc_layers = [{\u0026#34;indexing_str\u0026#34;: cur_layerstr, \u0026#34;module\u0026#34;: cur_module} for cur_layerstr, cur_module in decoder_model.named_modules() if isinstance(cur_module, nn.Linear)] # validate if the autoencoder model are symmetric assert len(encoder_fc_layers) == len(decoder_fc_layers) # tie weights for corresponding layers nof_fc_layers = len(encoder_fc_layers) for i_layer in range(nof_fc_layers): cur_encoder_layer = encoder_fc_layers[i_layer] cur_decoder_layer = decoder_fc_layers[nof_fc_layers - 1 - i_layer] # skip freezed (no grad) layers if needed if skip_no_grad_layer: if not cur_decoder_layer[\u0026#34;module\u0026#34;].weight.requires_grad: continue if not cur_decoder_layer[\u0026#34;module\u0026#34;].weight.requires_grad: continue # create tied linear module cur_tied_decoder_layermodule = WeightTiedLinear(cur_decoder_layer[\u0026#34;module\u0026#34;], cur_encoder_layer[\u0026#34;module\u0026#34;]) # update the corresponding layers cur_decoder_indexing_substrs = cur_decoder_layer[\u0026#34;indexing_str\u0026#34;].split(\u0026#39;.\u0026#39;) cur_nof_substrs = len(cur_decoder_indexing_substrs) cur_substr_slow_idx = 0 cur_substr_fast_idx = 0 # iterative access corresponding layers cur_model = decoder_model while(cur_substr_fast_idx \u0026lt; cur_nof_substrs): if cur_decoder_indexing_substrs[cur_substr_fast_idx].isdigit(): if cur_substr_fast_idx == cur_nof_substrs - 1: cur_model.get_submodule(\u0026#34;.\u0026#34;.join(cur_decoder_indexing_substrs[cur_substr_slow_idx:cur_substr_fast_idx]))[int(cur_decoder_indexing_substrs[cur_substr_fast_idx])] = cur_tied_decoder_layermodule else: cur_model = cur_model.get_submodule(\u0026#34;.\u0026#34;.join(cur_decoder_indexing_substrs[cur_substr_slow_idx:cur_substr_fast_idx]))[int(cur_decoder_indexing_substrs[cur_substr_fast_idx])] cur_substr_slow_idx = cur_substr_fast_idx + 1 cur_substr_fast_idx += 1 return encoder_model, decoder_model # untie weights for fully-connected network def untie_weight_fc_models( model: nn.Module, ): # get all fully connected layers # fc_layers = [{\u0026#34;indexing_str\u0026#34;: cur_layerstr, \u0026#34;module\u0026#34;: cur_module} for cur_layerstr, cur_module in model.named_modules() if isinstance(cur_module, WeightTiedLinear)] fc_layers = [{\u0026#34;indexing_str\u0026#34;: cur_layerstr, \u0026#34;module\u0026#34;: cur_module} for cur_layerstr, cur_module in model.named_modules() if type(cur_module).__name__ == \u0026#34;WeightTiedLinear\u0026#34;] # untie weights nof_fc_layers = len(fc_layers) for i_layer in range(nof_fc_layers): cur_layer = fc_layers[i_layer] # create linear module for each tied linear layer cur_untied_module = nn.Linear( in_features = cur_layer[\u0026#34;module\u0026#34;].weight.size(1), out_features = cur_layer[\u0026#34;module\u0026#34;].weight.size(0), bias = cur_layer[\u0026#34;module\u0026#34;].bias is None, device = cur_layer[\u0026#34;module\u0026#34;].weight.device, dtype = cur_layer[\u0026#34;module\u0026#34;].weight.dtype, ) # update linear module weight and bias from tied linear module cur_untied_module.weight = nn.Parameter(cur_layer[\u0026#34;module\u0026#34;].weight.clone()) cur_untied_module.bias = nn.Parameter(cur_layer[\u0026#34;module\u0026#34;].bias.clone()) # update the corresponding layers cur_indexing_substrs = cur_layer[\u0026#34;indexing_str\u0026#34;].split(\u0026#39;.\u0026#39;) cur_nof_substrs = len(cur_indexing_substrs) cur_substr_slow_idx = 0 cur_substr_fast_idx = 0 # iterative access corresponding layers cur_model = model while(cur_substr_fast_idx \u0026lt; cur_nof_substrs): if cur_indexing_substrs[cur_substr_fast_idx].isdigit(): if cur_substr_fast_idx == cur_nof_substrs - 1: cur_model.get_submodule(\u0026#34;.\u0026#34;.join(cur_indexing_substrs[cur_substr_slow_idx:cur_substr_fast_idx]))[int(cur_indexing_substrs[cur_substr_fast_idx])] = cur_untied_module else: cur_model = cur_model.get_submodule(\u0026#34;.\u0026#34;.join(cur_indexing_substrs[cur_substr_slow_idx:cur_substr_fast_idx]))[int(cur_indexing_substrs[cur_substr_fast_idx])] cur_substr_slow_idx = cur_substr_fast_idx + 1 cur_substr_fast_idx += 1 return model When tying a decoder layer to an encoder layer, we create a dummy linear layer that uses the weight of the corresponding encoder layer for forward and backward propagation. When untying the decoder layer, we create a new linear layer and update its weight and bias based on the dummy linear layer.\nUsing these tying and untying functions, we can tie and untie corresponding linear layers in the encoder and decoder as follows:\n1 2 3 4 5 6 # tie weights of encoder and decoder tie_weight_sym_fc_autoencoder(encoder, decoder) # untie weights untie_weight_fc_models(encoder) untie_weight_fc_models(decoder) Training Deep Autoencoder For deeper autoencoder networks, unsupervised training can be done in a greedy, layer-wise manner. We start by training the first layer of the encoder and the last layer of the decoder using the input and ground truth images. Once these layers are trained, we freeze them (disable their weight updates) and add the second layer of the encoder and the second-to-last layer of the decoder. We then train these new layers. This process is repeated until all the layers in the encoder and decoder have been trained. Finally, we fine-tune the entire network by training with weight updates enabled for all layers.\nThe layer state update, freezing, and unfreezing operations can be implemented using the following:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # get references of all the layer reference of a specific class def get_layer_refs( model: nn.Module, layer_class, ): # get all the fully connected layers # layers = [{\u0026#34;indexing_str\u0026#34;: cur_layerstr, \u0026#34;module\u0026#34;: cur_module} for cur_layerstr, cur_module in model.named_modules() if isinstance(cur_module, layer_class)] layers = [{\u0026#34;indexing_str\u0026#34;: cur_layerstr, \u0026#34;module\u0026#34;: cur_module} for cur_layerstr, cur_module in model.named_modules() if type(cur_module).__name__ == layer_class.__name__] return layers # update states of dst layers from src layers def update_corresponding_layers( src_layer_refs, dst_layer_refs, ): nof_src_layers = len(src_layer_refs) nof_dst_layers = len(dst_layer_refs) nof_itr_layers = min(nof_src_layers, nof_dst_layers) for i_layer in range(nof_itr_layers): cur_src_module = src_layer_refs[i_layer][\u0026#34;module\u0026#34;] cur_dst_module = dst_layer_refs[i_layer][\u0026#34;module\u0026#34;] cur_dst_module.load_state_dict(cur_src_module.state_dict()) return nof_src_layers, nof_dst_layers # freeze (disable grad calculation) all the layers in the input layer reference list def freeze_layers( layer_refs, ): for cur_layer in layer_refs: for param in cur_layer[\u0026#34;module\u0026#34;].parameters(): param.requires_grad = False return layer_refs # unfreeze (enable grad calculation) all the layers in the input layer reference list def unfreeze_layers( layer_refs, ): for cur_layer in layer_refs: for param in cur_layer[\u0026#34;module\u0026#34;].parameters(): param.requires_grad = True return layer_refs Using these functions, we can update a deep autoencoder network from a shallower pre trained autoencoder network and manage the freezing and unfreezing of layers as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # get layers src_encoder_fc_layer_refs = get_layer_refs(pretrain_encoder, torch.nn.Linear) dst_encoder_fc_layer_refs = get_layer_refs(encoder, torch.nn.Linear) src_decoder_fc_layer_refs = get_layer_refs(pretrain_decoder, torch.nn.Linear) dst_decoder_fc_layer_refs = get_layer_refs(decoder, torch.nn.Linear) src_decoder_fc_layer_refs = list(reversed(src_decoder_fc_layer_refs)) dst_decoder_fc_layer_refs = list(reversed(dst_decoder_fc_layer_refs)) ## update and freeze layers update_corresponding_layers(src_encoder_fc_layer_refs, dst_encoder_fc_layer_refs) freeze_layers(dst_encoder_fc_layer_refs[:len(src_encoder_fc_layer_refs)]) update_corresponding_layers(src_decoder_fc_layer_refs, dst_decoder_fc_layer_refs) freeze_layers(dst_decoder_fc_layer_refs[:len(src_decoder_fc_layer_refs)]) ## unfreeze layers unfreeze_layers(dst_encoder_fc_layer_refs) unfreeze_layers(dst_decoder_fc_layer_refs) The complete script for training the deep autoencoder can be found in the TrainDeepSimpleFCAutoencoder notebook in my GitHub repository.\nTips for Autoencoder Training Choosing the right activation function is crucial. When using the ReLU function without careful optimization, it can lead to the \u0026lsquo;dead ReLU\u0026rsquo; problem, causing inactive neurons in the autoencoder models.\nAvoiding a high learning rate during training, even with a scheduler (especially for autoencoders with lifetime sparsity constraints), is important. A large learning rate can cause gradient updates to overshoot in the initial epochs, potentially leading to undesired local minima during optimization.\nFor training deep autoencoder networks, especially those with sparse constraints, it\u0026rsquo;s beneficial to adopt a layer-by-layer iterative training approach. Training the network in stacked layers all at once can result in too few meaningful features in the latent space.\nApplications Compression and Dimension Reduction The dimension reduction application of the autoencoder network is straightforward. We use the encoder network to convert high-dimensional input data into low-dimensional representations. The decoder network then reconstructs the encoded information.\nAfter dimension reduction using the encoder, we can analyze the distribution of data in the latent space.\nThe two-dimensional codes found by a 784-128-64-32-2 fully-connected autoencoder. (image credit: Jian Zhong)\nDenoise Pixel-level noise and defects cannot efficiently be represented in the much lower-dimensional latent space, so autoencoders can also be applied for noise reduction and correcting pixel defects. To train an autoencoder network for denoising, we use images with added noise as input and clean images as ground truth.\nFor denoising with autoencoders, we apply Gaussian noise and masking noise as data transformations in PyTorch.\nThe Gaussian noise transformation can be implemented as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # Add gaussian noise to image pixel values class AddGaussianNoise(object): \u0026#34;\u0026#34;\u0026#34; Add gaussian noise to image pixel values \u0026#34;\u0026#34;\u0026#34; def __init__( self, mean = 0.0, variance = 1.0, generator = None, ): self.mean = mean self.variance = variance self.generator = generator # random number generator def __call__(self, src_image): src_image_shape = src_image.size() # generate random gaussian noise gauss_noise = torch.randn( size = src_image_shape, generator = self.generator, ) gauss_noise = self.mean + (self.variance ** 0.5) * gauss_noise # add guassian noise to image return src_image + gauss_noise def __repr__(self): return self.__class__.__name__ + f\u0026#34;(mean = {self.mean}, variance = {self.variance}, generator = {self.generator})\u0026#34; Here\u0026rsquo;s an example of denoising Gaussian noise using an autoencoder:\nGaussian denoise result of a simple fully-connected autoencoder (encoder: 784-64, decoder 64-784). (image credit: Jian Zhong)\nMasking noise involves randomly setting a fraction of pixels in the input image to zero.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # Rondomly choose pixels and set them to a constant value class RandomSetConstPxls(object): \u0026#34;\u0026#34;\u0026#34; Rondomly choose pixels and set them to a constant value \u0026#34;\u0026#34;\u0026#34; def __init__( self, rand_rate = 0.5, const_val = 0, ): self.rand_rate = rand_rate self.const_val = const_val def __call__(self, src_image): src_image_size = src_image.size() tot_nof_pxls = src_image.nelement() # calculate number of randomly choosed pixel nof_mod_pxls = tot_nof_pxls * self.rand_rate nof_mod_pxls = int(nof_mod_pxls) # generate mask for chosen pixels mod_pxl_mask = torch.full((tot_nof_pxls,), False) mod_pxl_mask[:nof_mod_pxls] = True mod_pxl_mask = mod_pxl_mask[torch.randperm(tot_nof_pxls)] # clone image and set the chosen pixels to corresponding contant value dst_image = src_image.clone() dst_image = dst_image.view(-1) dst_image[mod_pxl_mask] = self.const_val dst_image = dst_image.view(src_image_size) return dst_image def __repr__(self): return self.__class__.__name__ + f\u0026#34;(rand_rate = {self.rand_rate}, const_val = {self.const_val})\u0026#34; Here\u0026rsquo;s an example of using a simple fully-connected autoencoder to denoise masked noise:\nMask denoise result of a simple fully-connected autoencoder (encoder: 784-64, decoder 64-784). (image credit: Jian Zhong)\nRefer to the TrainSimpleDenoiseFCAutoencoder Jupyter notebook in my GitHub repository for more details.\nFeature extraction and semi-supervised learning When training an autoencoder to transform input data into a low-dimensional space, the encoder and decoder learn to map input data to a latent space and reconstruct it back. The encoder and decoder inherently capture essential features from the data through these transformations.\nThis feature extraction capability of autoencoders makes them highly effective for semi-supervised learning scenarios. In semi-supervised learning for classification networks, for instance, we can first train an autoencoder using the abundant unlabeled data. Subsequently, we connect a shallow fully-connected network after the encoder of the autoencoder. We then use the limited labeled data to fine-tune this shallow network.\nReference [1] Hinton, G. E. \u0026amp; Salakhutdinov, R. R. Reducing the Dimensionality of Data with Neural Networks. Science 313, 504–507 (2006).\n[2] Kramer, M. A. Nonlinear principal component analysis using autoassociative neural networks. AIChE Journal 37, 233–243 (1991).\n[3] Masci, J., Meier, U., Cireşan, D. \u0026amp; Schmidhuber, J. Stacked Convolutional Auto-Encoders for hierarchical feature extraction. in Lecture notes in computer science 52–59 (2011). doi:10.1007/978-3-642-21735-7_7.\n[4] Makhzani, A. \u0026amp; Frey, B. J. A Winner-Take-All method for training sparse convolutional autoencoders. arXiv (Cornell University) (2014).\n[5] A. Ng, “Sparse autoencoder,” CS294A Lecture notes, vol. 72, 2011.\nCitation If you found this article helpful, please cite it as:\nZhong, Jian (June 2024). Autoencoders with PyTorch: Full Code Guide. Vision Tech Insights. https://jianzhongdev.github.io/VisionTechInsights/posts/autoencoders_with_pytorch_full_code_guide/.\nOr\n@article{zhong2024buildtrainVGGPyTorch, title = \u0026#34;Autoencoders with PyTorch: Full Code Guide\u0026#34;, author = \u0026#34;Zhong, Jian\u0026#34;, journal = \u0026#34;jianzhongdev.github.io\u0026#34;, year = \u0026#34;2024\u0026#34;, month = \u0026#34;June\u0026#34;, url = \u0026#34;https://jianzhongdev.github.io/VisionTechInsights/posts/autoencoders_with_pytorch_full_code_guide/\u0026#34; } ","permalink":"http://localhost:1313/posts/autoencoders_with_pytorch_full_code_guide/","summary":"An autoencoder is a type of artificial neural network that learns to create efficient codings, or representations, of unlabeled data, making it useful for unsupervised learning. Autoencoders can be used for tasks like reducing the number of dimensions in data, extracting important features, and removing noise. They\u0026rsquo;re also important for building semi-supervised learning models and generative models. The concept of autoencoders has inspired many advanced models.\nIn this blog post, we\u0026rsquo;ll start with a simple introduction to autoencoders.","title":"Autoencoders with PyTorch: Full Code Guide"},{"content":"When creating high-speed data streaming applications, it\u0026rsquo;s important to avoid unnecessary data transfer to keep things fast and efficient. Operating systems (OS) automatically buffer file input/output (I/O) in the computer\u0026rsquo;s memory. However, many data streaming applications already have their own buffering steps, making the OS\u0026rsquo;s additional buffering unnecessary. Disabling this OS buffering allows direct control of data transfer, but it requires the application to access data in sizes that are multiples of the system page size (or disk sector size).\nThis blog post will show you how to build a C++ data structure called PageContainer that lets you access data without the OS buffering. You can find the ready-to-use source code for PageContainer in my Github repository.(URL: https://github.com/JianZhongDev/PageContainer )\nContainer Class Requirements For applications that need to read and write large amounts of data without OS buffering, the data container should meet the following requirements:\nThe buffer size should be a multiple of the page size. It should be able to store data whose size does not perfectly match multiples of the page size It should be capable of saving multiple containers within a large file. The PageContainer Class To meet the requirements for accessing data without OS buffering, we can create a PageContainer class. The following sections will explain each part of this class in detail.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 namespace Container{ typedef int errflag_t; static const errflag_t ERR_NULL = 0; static const errflag_t SUCCESS = 1; static const errflag_t ERR_FAILED = -1; static const errflag_t ERR_MEMERR = -2; // return errflag for fast error handling template\u0026lt;typename dtype\u0026gt; class PageContainer { private: void* buffer_p = nullptr; size_t* buffer_size_p = nullptr; dtype* data_p = nullptr; size_t* data_size_p = nullptr; bool allocated_buffer = false; // assign data pointers insider buffer errflag_t assign_pointers() { if (this-\u0026gt;buffer_p != nullptr) { this-\u0026gt;buffer_size_p = (size_t*)this-\u0026gt;buffer_p; this-\u0026gt;data_size_p = ((size_t*)this-\u0026gt;buffer_p) + 1; this-\u0026gt;data_p = (dtype*)(((size_t*)this-\u0026gt;buffer_p) + 2); return SUCCESS; } return ERR_FAILED; } // initialize buffer and data pointers errflag_t init_buffer(size_t buffer_size) { errflag_t err_flag = ERR_NULL; if (this-\u0026gt;buffer_p == nullptr) { // allocate buffer this-\u0026gt;buffer_p = malloc(buffer_size); if (this-\u0026gt;buffer_p == nullptr) return ERR_MEMERR; memset(this-\u0026gt;buffer_p, 0, buffer_size); // assign pointers err_flag = this-\u0026gt;assign_pointers(); // update type *(this-\u0026gt;buffer_size_p) = buffer_size; *(this-\u0026gt;data_size_p) = 0; } this-\u0026gt;allocated_buffer = true; return err_flag; } // free allocated buffer errflag_t free_buffer() { if (this-\u0026gt;allocated_buffer) { // free buffer only when object allocated the buffer. if (this-\u0026gt;buffer_p != nullptr) { free(this-\u0026gt;buffer_p); } } return SUCCESS; } public: // constructor from existing buffer PageContainer(void* input_buffer_p, bool new_buffer = true) { errflag_t errflag = ERR_NULL; size_t buffer_size = *((size_t*)input_buffer_p); if (new_buffer) { errflag = this-\u0026gt;init_buffer(buffer_size); memcpy(this-\u0026gt;buffer_p, input_buffer_p, buffer_size); } else { this-\u0026gt;buffer_p = input_buffer_p; errflag = this-\u0026gt;assign_pointers(); } // throw error when failed if (errflag != SUCCESS) { throw std::runtime_error(\u0026#34;PageContainer failed to init. Error flag = \u0026#34; + std::to_string(errflag)); } } // constructor by giving max data size PageContainer(size_t capacity, size_t page_size) { errflag_t errflag = ERR_NULL; size_t nof_pages = (capacity + 2 * sizeof(size_t)) / page_size; if ((capacity + 2 * sizeof(size_t)) % page_size \u0026gt; 0) nof_pages += 1; size_t buffer_size = nof_pages * page_size; errflag = this-\u0026gt;init_buffer(buffer_size); // throw error when failed if (errflag != SUCCESS) { throw std::runtime_error(\u0026#34;PageContainer failed to init. Error flag = \u0026#34; + std::to_string(errflag)); } } // constructor by giving buffer size PageContainer(size_t buffer_size) { errflag_t errflag = ERR_NULL; errflag = this-\u0026gt;init_buffer(buffer_size); // throw error when failed if (errflag != SUCCESS) { throw std::runtime_error(\u0026#34;PageContainer failed to init. Error flag = \u0026#34; + std::to_string(errflag)); } } // destuctor frees memory ~PageContainer() { this-\u0026gt;free_buffer(); } // get the buffer pointer and size errflag_t get_buffer(void** buf_pp, size_t* buf_size_p) { *buf_pp = this-\u0026gt;buffer_p; *buf_size_p = *(this-\u0026gt;buffer_size_p); return SUCCESS; } // get data pointer errflag_t get_data_p(dtype** data_pp) { *data_pp = this-\u0026gt;data_p; return SUCCESS; } // get capacity errflag_t get_capacity(size_t* capacity_p) { size_t capacity = *(this-\u0026gt;buffer_size_p) - 2 * sizeof(size_t); *capacity_p = capacity; return SUCCESS; } // get data size errflag_t get_data_size(size_t* data_size_p) { *data_size_p = *(this-\u0026gt;data_size_p); return SUCCESS; } // set data size errflag_t set_data_size(size_t data_size) { errflag_t err_flag = ERR_NULL; size_t capacity = 0; err_flag = this-\u0026gt;get_capacity(\u0026amp;capacity); if (err_flag != SUCCESS) return err_flag; if (data_size \u0026gt; capacity) { return ERR_FAILED; } *(this-\u0026gt;data_size_p) = data_size; return SUCCESS; } }; } Data structure As shown in the cover image of this post, the main storage space of the PageContainer is a buffer sized as a multiple of the system page size. The first sizeof(size_t) bytes (8 bytes on 64-bit systems, 4 bytes on 32-bit systems) store the total size of the buffer. The next sizeof(size_t) bytes store the size of the valid data. The remaining space is used for data storage. Pointers are assigned for the entire buffer, the buffer size, the data size, and the data storage area.\nThis data structure setup allows data access without OS buffering and lets you store data that isn\u0026rsquo;t an exact multiple of the page size. By storing the buffer size and data size for each PageContainer object, you can store and access multiple PageContainer buffers within a single file without needing extra metadata.\nCreating and deleting a PageContainer When creating a PageContainer object, it allocates a buffer and organizes it based on the structure described earlier. The methods assign_pointers() and init_buffer() handle the allocation of the buffer and set up the necessary pointers.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // assign data pointers insider buffer errflag_t assign_pointers() { if (this-\u0026gt;buffer_p != nullptr) { this-\u0026gt;buffer_size_p = (size_t*)this-\u0026gt;buffer_p; this-\u0026gt;data_size_p = ((size_t*)this-\u0026gt;buffer_p) + 1; this-\u0026gt;data_p = (dtype*)(((size_t*)this-\u0026gt;buffer_p) + 2); return SUCCESS; } return ERR_FAILED; } // initialize buffer and data pointers errflag_t init_buffer(size_t buffer_size) { errflag_t err_flag = ERR_NULL; if (this-\u0026gt;buffer_p == nullptr) { // allocate buffer this-\u0026gt;buffer_p = malloc(buffer_size); if (this-\u0026gt;buffer_p == nullptr) return ERR_MEMERR; memset(this-\u0026gt;buffer_p, 0, buffer_size); // assign pointers err_flag = this-\u0026gt;assign_pointers(); // update type *(this-\u0026gt;buffer_size_p) = buffer_size; *(this-\u0026gt;data_size_p) = 0; } this-\u0026gt;allocated_buffer = true; return err_flag; } With the methods for buffer allocation and arrangement in place, the constructors of the PageContainer can be defined simply as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // constructor by giving buffer size PageContainer(size_t buffer_size) { errflag_t errflag = ERR_NULL; errflag = this-\u0026gt;init_buffer(buffer_size); // throw error when failed if (errflag != SUCCESS) { throw std::runtime_error(\u0026#34;PageContainer failed to init. Error flag = \u0026#34; + std::to_string(errflag)); } } // constructor by giving max data size PageContainer(size_t capacity, size_t page_size) { errflag_t errflag = ERR_NULL; size_t nof_pages = (capacity + 2 * sizeof(size_t)) / page_size; if ((capacity + 2 * sizeof(size_t)) % page_size \u0026gt; 0) nof_pages += 1; size_t buffer_size = nof_pages * page_size; errflag = this-\u0026gt;init_buffer(buffer_size); // throw error when failed if (errflag != SUCCESS) { throw std::runtime_error(\u0026#34;PageContainer failed to init. Error flag = \u0026#34; + std::to_string(errflag)); } } Here, the first constructor accepts a directly calculated buffer size (buffer_size) from external sources. The second constructor takes expected maximum data size (capacity, in bytes) and system page size (page_size, in bytes) as inputs, calculating the minimum required buffer size accordingly.\nIn some applications, such as when loading a PageContainer buffer from a file or using intermediate buffering, there may already be memory allocated to store the buffer. In these cases, where pre-existing buffers are available, PageContainer also provides constructors that use these buffers directly, without allocating additional space.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // constructor from existing buffer PageContainer(void* input_buffer_p, bool new_buffer = true) { errflag_t errflag = ERR_NULL; size_t buffer_size = *((size_t*)input_buffer_p); if (new_buffer) { errflag = this-\u0026gt;init_buffer(buffer_size); memcpy(this-\u0026gt;buffer_p, input_buffer_p, buffer_size); } else { this-\u0026gt;buffer_p = input_buffer_p; errflag = this-\u0026gt;assign_pointers(); } // throw error when failed if (errflag != SUCCESS) { throw std::runtime_error(\u0026#34;PageContainer failed to init. Error flag = \u0026#34; + std::to_string(errflag)); } } To properly manage the dynamically allocated buffer, we have also defined the free_buffer() method as follows.\n1 2 3 4 5 6 7 8 9 // free allocated buffer errflag_t free_buffer() { if (this-\u0026gt;allocated_buffer) { // free buffer only when object allocated the buffer. if (this-\u0026gt;buffer_p != nullptr) { free(this-\u0026gt;buffer_p); } } return SUCCESS; } In the PageContainer destructor, the buffer is freed if it was allocated during construction.\n1 2 3 4 // destuctor frees memory ~PageContainer() { this-\u0026gt;free_buffer(); } Accessing data and buffer In data streaming applications, it\u0026rsquo;s common to have APIs that accept pointers to storage spaces for reading and writing data. Here\u0026rsquo;s a typical pesudo code of how such an API might be structured:\n1 2 errorflag_t write_data(handle_t file_handle, void* src_buffer, size_t bytes_to_write); errorflag_t read_data(handle_t file_handle, void* dst_buffer, size_t bytes_to_read, size_t* bytes_retrieved); Examples of such APIs include functions like WriteFile and ReadFile provided by the Windows API.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 BOOL WriteFile( [in] HANDLE hFile, [in] LPCVOID lpBuffer, [in] DWORD nNumberOfBytesToWrite, [out, optional] LPDWORD lpNumberOfBytesWritten, [in, out, optional] LPOVERLAPPED lpOverlapped ); BOOL ReadFile( [in] HANDLE hFile, [out] LPVOID lpBuffer, [in] DWORD nNumberOfBytesToRead, [out, optional] LPDWORD lpNumberOfBytesRead, [in, out, optional] LPOVERLAPPED lpOverlapped ); PageContainer offers the following methods to access data stored within it following such pointer data IO scheme.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // get data pointer errflag_t get_data_p(dtype** data_pp) { *data_pp = this-\u0026gt;data_p; return SUCCESS; } // get capacity errflag_t get_capacity(size_t* capacity_p) { size_t capacity = *(this-\u0026gt;buffer_size_p) - 2 * sizeof(size_t); *capacity_p = capacity; return SUCCESS; } // get data size errflag_t get_data_size(size_t* data_size_p) { *data_size_p = *(this-\u0026gt;data_size_p); return SUCCESS; } // set data size errflag_t set_data_size(size_t data_size) { errflag_t err_flag = ERR_NULL; size_t capacity = 0; err_flag = this-\u0026gt;get_capacity(\u0026amp;capacity); if (err_flag != SUCCESS) return err_flag; if (data_size \u0026gt; capacity) { return ERR_FAILED; } *(this-\u0026gt;data_size_p) = data_size; return SUCCESS; } The get_data_p() method provides a pointer to the storage space where data is stored. The get_capacity() method provides the maximum amount of data, in bytes, that the PageContainer can hold. The get_data_size() method provides the current size of the stored data in bytes. The set_data_size() method provides the size of the stored data when new data is written into the PageContainer.\nFor reading and writing operations that require data sizes to be multiples of the page size, PageContainer offers the following method to access the entire allocated buffer.\n1 2 3 4 5 6 // get the buffer pointer and size errflag_t get_buffer(void** buf_pp, size_t* buf_size_p) { *buf_pp = this-\u0026gt;buffer_p; *buf_size_p = *(this-\u0026gt;buffer_size_p); return SUCCESS; } Using PageContainer Here\u0026rsquo;s a quick example demonstrating how to use the PageContainer:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 void main() { std::wstring file_path = L\u0026#34;test_file.bin\u0026#34;; HANDLE file_handle = INVALID_HANDLE_VALUE; size_t page_size = 4 * 1024; // initial 4KB page size Container::errflag_t errflag = Container::ERR_NULL; DWORD error_flag = NULL; DWORD d_error = NULL; // get system page size SYSTEM_INFO sys_info; GetSystemInfo(\u0026amp;sys_info); page_size = sys_info.dwPageSize; std::cout \u0026lt;\u0026lt; \u0026#34;system page size: \u0026#34; \u0026lt;\u0026lt; page_size \u0026lt;\u0026lt; std::endl; // initialize test array const size_t array_len = 10; float* test_array = new float[array_len]; size_t data_size = array_len * sizeof(float); for (size_t idx = 0; idx \u0026lt; array_len; ++idx) { test_array[idx] = rand_float(0.0f, 1.0f, 1000); } std::cout \u0026lt;\u0026lt; \u0026#34;write array: \u0026#34; \u0026lt;\u0026lt; carray_to_string(test_array, array_len) \u0026lt;\u0026lt; std::endl; // create container with page size Container::PageContainer\u0026lt;float\u0026gt; write_container(array_len * sizeof(float), page_size); // copy data into container size_t data_size_to_write = data_size; float* write_data_p = nullptr; size_t write_capacity = 0; errflag = write_container.get_data_p(\u0026amp;write_data_p); if (errflag != Container::SUCCESS) { std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t failed to access data pointer.\u0026#34; \u0026lt;\u0026lt; std::endl; } write_container.get_capacity(\u0026amp;write_capacity); memcpy(write_data_p, test_array, data_size_to_write); write_container.set_data_size(data_size_to_write); // write data to file (bypassing system buffer) // open file file_handle = CreateFileW( file_path.c_str(), GENERIC_WRITE | GENERIC_READ, 0, NULL, CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL | FILE_FLAG_NO_BUFFERING, NULL); if (file_handle == INVALID_HANDLE_VALUE) { std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t failed to create file.\u0026#34; \u0026lt;\u0026lt; std::endl; return; } void* write_buffer_p = nullptr; size_t write_buffer_size = 0; write_container.get_buffer(\u0026amp;write_buffer_p, \u0026amp;write_buffer_size); // write data error_flag = WriteFile(file_handle, write_buffer_p, write_buffer_size, NULL, NULL); d_error = GetLastError(); if (error_flag == FALSE \u0026amp;\u0026amp; d_error != ERROR_IO_PENDING) { std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t error in write file, error code = \u0026#34; \u0026lt;\u0026lt; d_error \u0026lt;\u0026lt; std::endl; return; } // close file CloseHandle(file_handle); file_handle = INVALID_HANDLE_VALUE; std::cout \u0026lt;\u0026lt; \u0026#34;data write to: \u0026#34;; std::wcout \u0026lt;\u0026lt; file_path; std::cout \u0026lt;\u0026lt; std::endl; // read data from file void* read_buffer_p = nullptr; size_t read_buffer_size = 0; DWORD bytes_read = 0; // open file file_handle = CreateFileW( file_path.c_str(), GENERIC_READ, 0, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL); if (file_handle == INVALID_HANDLE_VALUE) { std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t failed to create file.\u0026#34; \u0026lt;\u0026lt; std::endl; return; } // get buffer size error_flag = ReadFile(file_handle, \u0026amp;read_buffer_size, sizeof(size_t), \u0026amp;bytes_read, NULL); d_error = GetLastError(); if (error_flag == FALSE \u0026amp;\u0026amp; d_error != ERROR_IO_PENDING) { std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t error in read file, error code = \u0026#34; \u0026lt;\u0026lt; d_error \u0026lt;\u0026lt; std::endl; return; } std::cout \u0026lt;\u0026lt; \u0026#34;read_buffer_size = \u0026#34; \u0026lt;\u0026lt; read_buffer_size \u0026lt;\u0026lt; std::endl; Container::PageContainer\u0026lt;float\u0026gt; read_container(read_buffer_size); read_container.get_buffer(\u0026amp;read_buffer_p, \u0026amp;read_buffer_size); // set file pointer to start of the buffer SetFilePointer(file_handle, 0, NULL, FILE_BEGIN); d_error = GetLastError(); if (d_error != 0) { std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t error set file pointer, error code = \u0026#34; \u0026lt;\u0026lt; d_error \u0026lt;\u0026lt; std::endl; return; } // load buffer from the file error_flag = ReadFile(file_handle, read_buffer_p, read_buffer_size, \u0026amp;bytes_read, NULL); d_error = GetLastError(); if (error_flag == FALSE \u0026amp;\u0026amp; d_error != ERROR_IO_PENDING) { std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t error in read file, error code = \u0026#34; \u0026lt;\u0026lt; d_error \u0026lt;\u0026lt; std::endl; return; } // close file CloseHandle(file_handle); file_handle = INVALID_HANDLE_VALUE; std::cout \u0026lt;\u0026lt; \u0026#34;data read from: \u0026#34;; std::wcout \u0026lt;\u0026lt; file_path; std::cout \u0026lt;\u0026lt; std::endl; // display read data float* read_arr = nullptr; size_t read_data_size = 0; size_t read_arr_len = 0; read_container.get_data_p(\u0026amp;read_arr); read_container.get_data_size(\u0026amp;read_data_size); read_arr_len = read_data_size / sizeof(float); std::cout \u0026lt;\u0026lt; \u0026#34;read array: \u0026#34; \u0026lt;\u0026lt; carray_to_string(read_arr, read_arr_len) \u0026lt;\u0026lt; std::endl; } In this example, we start by creating a PageContainer object (write_container) to store a float test array. The size of this array doesn\u0026rsquo;t match the system\u0026rsquo;s page size. We use the memcpy() function explicitly in the example to copy data into the PageContainer object. Next, we create a file with the FILE_FLAG_NO_BUFFERING flag, which disables Windows\u0026rsquo; OS file buffering. We then write the entire buffer of the PageContainer object to this file and close it.\nLastly, we reopen the saved file to read the buffer size. Using this size, we create a new PageContainer object (read_container) and load the buffer from the file. Finally, we retrieve the array from the read_container.\nThe output displayed in the terminal for the demo code above is as follows:\nsystem page size: 4096\rwrite array: {0.041, 0.467, 0.334, 0.5, 0.169, 0.724, 0.478, 0.358, 0.962, 0.464}\rdata write to: test_file.bin\rread_buffer_size = 4096\rdata read from: test_file.bin\rread array: {0.041, 0.467, 0.334, 0.5, 0.169, 0.724, 0.478, 0.358, 0.962, 0.464} Conclusion By allocating a memory space sized in multiples of page sizes and organizing it into sections for storing buffer size, data size, and actual data, we created the PageContainer class. This setup enables direct reading and writing of data without relying on OS buffering.\nCitation If you found this article helpful, please cite it as:\nZhong, Jian (June 2024). PageContainer: Fast, Direct Data I/O Without OS Buffering. Vision Tech Insights. https://jianzhongdev.github.io/VisionTechInsights/posts/page_container_direct_data_io/.\nOr\n@article{zhong2024pagecontainer, title = \u0026#34;PageContainer: Fast, Direct Data I/O Without OS Buffering\u0026#34;, author = \u0026#34;Zhong, Jian\u0026#34;, journal = \u0026#34;jianzhongdev.github.io\u0026#34;, year = \u0026#34;2024\u0026#34;, month = \u0026#34;June\u0026#34;, url = \u0026#34;https://jianzhongdev.github.io/VisionTechInsights/posts/building_a_configuration_file_parser_with_cpp/.\u0026#34; } ","permalink":"http://localhost:1313/posts/page_container_direct_data_io/","summary":"When creating high-speed data streaming applications, it\u0026rsquo;s important to avoid unnecessary data transfer to keep things fast and efficient. Operating systems (OS) automatically buffer file input/output (I/O) in the computer\u0026rsquo;s memory. However, many data streaming applications already have their own buffering steps, making the OS\u0026rsquo;s additional buffering unnecessary. Disabling this OS buffering allows direct control of data transfer, but it requires the application to access data in sizes that are multiples of the system page size (or disk sector size).","title":"PageContainer: Fast, Direct Data I/O Without OS Buffering"},{"content":"The VGG (Visual Geometry Group) model is a type of convolutional neural network (CNN) outlined in the paper Very Deep Convolutional Networks for Large-Scale Image Recognition. It\u0026rsquo;s known for its use of small convolution filters and deep layers, which helped it achieve top-notch performance in tasks like image classification. By stacking multiple layers with small kernel sizes, VGG can capture a wide range of features from input images. Plus, adding more rectification layers makes its decision-making process sharper and more accurate. The paper also introduced 1x1 convolutional layers to enhance nonlinearity without affecting the receptive view. For training, VGG follows the traditional supervised learning approach where input images and ground truth labels are provided.\nVGG\u0026rsquo;s architecture has significantly shaped the field of neural networks, serving as a foundation and benchmark for many subsequent models in computer vision.\nIn this blog post, we\u0026rsquo;ll guide you through implementing and training the VGG architecture using PyTorch, step by step. You can find the complete code for defining and training the VGG model on my GitHub repository (URL: https://github.com/JianZhongDev/VGGPyTorch ).\nVGG Architecture and Implementation As you can see in the cover image of this post, the VGG model is made up of multiple layers of convolution followed by max-pooling, and it ends with a few fully connected layers. The output from these layers is then fed into a softmax layer to give a normalized confidence score for each image category.\nThe key features of the VGG network are these stacked convolutional layers and fully connected layers. We will start with these stacked layers in our implementation.\nStacked Convolutional Layers To start, we\u0026rsquo;ll create the stacked convolutional layer as PyTorch nn.Module, like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 # stacked 2D convolutional layer class VGGStacked2DConv(nn.Module): def __init__( self, layer_descriptors = [], ): assert(isinstance(layer_descriptors, list)) super().__init__() self.network = nn.Identity() # create list of stacked layers stacked_layers = [] # iterater through each descriptor for the layers and create corresponding layers prev_out_channels = 1 for i_descrip in range(len(layer_descriptors)): cur_descriptor = layer_descriptors[i_descrip] # the descriptor needs to be dict if not isinstance(cur_descriptor, dict): continue # get input or default values nof_layers = cur_descriptor.get(\u0026#34;nof_layers\u0026#34;, 1) in_channels = cur_descriptor.get(\u0026#34;in_channels\u0026#34;, prev_out_channels) out_channels = cur_descriptor.get(\u0026#34;out_channels\u0026#34;, 1) kernel_size = cur_descriptor.get(\u0026#34;kernel_size\u0026#34;, 3) stride = cur_descriptor.get(\u0026#34;stride\u0026#34;, 1) padding = cur_descriptor.get(\u0026#34;padding\u0026#34;, 1) bias = cur_descriptor.get(\u0026#34;bias\u0026#34;, True) padding_mode = cur_descriptor.get(\u0026#34;padding_mode\u0026#34;, \u0026#34;zeros\u0026#34;) activation = cur_descriptor.get(\u0026#34;activation\u0026#34;, nn.ReLU) # create layers cur_in_channels = in_channels for _ in range(nof_layers): stacked_layers.append( nn.Conv2d( in_channels = cur_in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = stride, padding = padding, bias = bias, padding_mode = padding_mode, ) ) stacked_layers.append( activation() ) cur_in_channels = out_channels prev_out_channels = out_channels # convert list of layers to sequential layers if len(stacked_layers) \u0026gt; 0: self.network = nn.Sequential(*stacked_layers) def forward(self, x): y = self.network(x) return y The stacked convolutional layer takes in a list of descriptor dictionaries, each detailing the setup for a repeated convolutional layer followed by an activation. It reads these configurations and builds the stacked convolutional layers accordingly. If certain configuration parameters are not specified, the code fills in default values.\nStacked Fully-Connected and Dropout Layers VGG uses dropout regularizations in their fully connected layers. Adding the dropout regularization within PyTorch is straightforward: we just need to insert dropout layers after each hidden layer inside the stacked fully connected layer. (NOTE: Section 4.2 of the AlexNet paper provides valuable insights into dropout layers. It\u0026rsquo;s definitely worth a read.)\nWe can define the stacked fully connected layer in a similar manner as the stacked convolutional layers:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 # stacked linear layers class VGGStackedLinear(nn.Module): def __init__( self, layer_descriptors = [], ): assert(isinstance(layer_descriptors, list)) super().__init__() self.network = nn.Identity() # create list of stacked layers stacked_layers = [] # iterater through each descriptor for the layers and create corresponding layers prev_out_features = 1 for i_descrip in range(len(layer_descriptors)): cur_descriptor = layer_descriptors[i_descrip] # the descriptor needs to be dict if not isinstance(cur_descriptor, dict): continue nof_layers = cur_descriptor.get(\u0026#34;nof_layers\u0026#34;, 1) in_features = cur_descriptor.get(\u0026#34;in_features\u0026#34;, prev_out_features) out_features = cur_descriptor.get(\u0026#34;out_features\u0026#34;, 1) bias = cur_descriptor.get(\u0026#34;bias\u0026#34;, True) activation = cur_descriptor.get(\u0026#34;activation\u0026#34;, nn.ReLU) dropout_p = cur_descriptor.get(\u0026#34;dropout_p\u0026#34;, None) # create layers cur_in_features = in_features for _ in range(nof_layers): stacked_layers.append( nn.Linear( in_features = cur_in_features, out_features = out_features, bias = bias, ) ) if activation is not None: stacked_layers.append( activation() ) if dropout_p is not None: stacked_layers.append( nn.Dropout(p = dropout_p) ) cur_in_features = out_features prev_out_features = out_features # convert list of layers to sequential layers if len(stacked_layers) \u0026gt; 0: self.network = nn.Sequential(*stacked_layers) def forward(self, x): y = self.network(x) return y VGG Model Now that we\u0026rsquo;ve defined the stacked convolutional and fully-connected layers, we can construct the VGG model as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 # VGG model definition class VGG(nn.Module): def __init__( self, stacked_conv_descriptors, stacked_linear_descriptor, ): assert(isinstance(stacked_conv_descriptors, list)) assert(isinstance(stacked_linear_descriptor, list)) super().__init__() self.network = nn.Identity() stacked_layers = [] # add stacked convolutional layers and max pooling layers for i_stackconv_descrip in range(len(stacked_conv_descriptors)): cur_stacked_conv_descriptor = stacked_conv_descriptors[i_stackconv_descrip] if not isinstance(cur_stacked_conv_descriptor, list): continue stacked_layers.append( StackedLayers.VGGStacked2DConv( cur_stacked_conv_descriptor ) ) # add max pooling layer after stacked convolutional layer stacked_layers.append( nn.MaxPool2d( kernel_size = 2, stride = 2, ) ) # flatten convolutional layers stacked_layers.append( nn.Flatten() ) # add stacked linear layers stacked_layers.append( StackedLayers.VGGStackedLinear( stacked_linear_descriptor ) ) # add softmax layer at the very end stacked_layers.append( nn.Softmax(dim = -1) ) # convert list of layers to Sequantial network if len(stacked_layers) \u0026gt; 0: self.network = nn.Sequential(*stacked_layers) def forward(self, x): y = self.network(x) return y The VGG model takes in a stacked convolutional layer descriptor list, and a fully connected layer descriptor. First, it goes through the convolutional layer descriptors, creating stacked convolutional layers for each descriptor and adding a max pooling layer after each set of stacked convolutional layers. Then, it flattens the output from all the convolutional layers and constructs stacked fully connected layers based on the linear layer descriptor. Finally, a Softmax layer is appended at the end of the network.\nModel Generation Using the model definition provided above, we can create a VGG model by specifying a few layer descriptors. For instance, we can replicate the VGG16 model described in the VGG paper as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ## Demo creating 16-layer VGG model input_image_width = 224 input_image_height = 224 model_stacked_conv_list = [ [ {\u0026#34;nof_layers\u0026#34;: 2, \u0026#34;in_channels\u0026#34;: 3, \u0026#34;out_channels\u0026#34;: 64,}, ], [ {\u0026#34;nof_layers\u0026#34;: 2, \u0026#34;in_ckjhannels\u0026#34;: 64, \u0026#34;out_channels\u0026#34;: 128,}, ], [ {\u0026#34;nof_layers\u0026#34;: 2, \u0026#34;in_channels\u0026#34;: 128, \u0026#34;out_channels\u0026#34;: 256, }, {\u0026#34;nof_layers\u0026#34;: 1, \u0026#34;out_channels\u0026#34;: 256, \u0026#34;kernel_size\u0026#34;: 1, \u0026#34;padding\u0026#34;: 0}, ], [ {\u0026#34;nof_layers\u0026#34;: 2, \u0026#34;in_ckjhannels\u0026#34;: 256, \u0026#34;out_channels\u0026#34;: 512,}, {\u0026#34;nof_layers\u0026#34;: 1, \u0026#34;out_channels\u0026#34;: 512, \u0026#34;kernel_size\u0026#34;: 1, \u0026#34;padding\u0026#34;: 0}, ], [ {\u0026#34;nof_layers\u0026#34;: 2, \u0026#34;in_ckjhannels\u0026#34;: 512, \u0026#34;out_channels\u0026#34;: 512,}, {\u0026#34;nof_layers\u0026#34;: 1, \u0026#34;out_channels\u0026#34;: 512, \u0026#34;kernel_size\u0026#34;: 1, \u0026#34;padding\u0026#34;: 0}, ], ] conv_image_reduce_ratio = 2**len(model_stacked_conv_list) conv_final_image_width = input_image_width//conv_image_reduce_ratio conv_final_image_height = input_image_height//conv_image_reduce_ratio model_stacked_linear = [ { \u0026#34;nof_layers\u0026#34;: 2, \u0026#34;in_features\u0026#34;: conv_final_image_width * conv_final_image_height * 512, \u0026#34;out_features\u0026#34;: 4096, \u0026#34;dropout_p\u0026#34;: 0.5 }, { \u0026#34;nof_layers\u0026#34;: 1, \u0026#34;out_features\u0026#34;: 1000, \u0026#34;activation\u0026#34;: None } ] model = VGG.VGG( stacked_conv_descriptors = model_stacked_conv_list, stacked_linear_descriptor = model_stacked_linear, enable_debug = False, ) print(model) Here\u0026rsquo;s what the printout of the VGG16 model looks like:\nclick to expand 16-layer VGG model printout\rVGG( (network): Sequential( (0): VGGStacked2DConv( (network): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU() ) ) (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (2): VGGStacked2DConv( (network): Sequential( (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU() ) ) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): VGGStacked2DConv( (network): Sequential( (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU() (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1)) (5): ReLU() ) ) (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (6): VGGStacked2DConv( (network): Sequential( (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU() (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1)) (5): ReLU() ) ) (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (8): VGGStacked2DConv( (network): Sequential( (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU() (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1)) (5): ReLU() ) ) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Flatten(start_dim=1, end_dim=-1) (11): VGGStackedLinear( (network): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU() (2): Dropout(p=0.5, inplace=False) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU() (5): Dropout(p=0.5, inplace=False) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) (12): Softmax(dim=-1) ) ) Data Processing In the VGG paper, the only data processing done on the input data is subtracting the RGB value calculated from the training set. To apply this processing, we start by going through the entire training dataset and computing the mean value for each color channel.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## calculated the averaged channel values across the entire data set # train_dataloader is the dataloader iterating through the entire training data set input_dataloader = train_dataloader nof_batchs = len(input_dataloader) avg_ch_vals = [None for _ in range(nof_batchs)] for i_batch, data in enumerate(input_dataloader): inputs, labels = data cur_avg_ch = torch.mean(inputs, dim = (-1,-2), keepdim = True) avg_ch_vals[i_batch] = cur_avg_ch avg_ch_vals = torch.cat(avg_ch_vals, dim = 0) avg_ch_val = torch.mean(avg_ch_vals, dim = 0, keepdim = False) print(\u0026#34;result size = \u0026#34;) print(avg_ch_val.size()) print(\u0026#34;result val = \u0026#34;) print(repr(avg_ch_val)) Using the mean channel value, we can perform the mentioned data processing by defining a background subtraction function and using the Lambda() transform provided by torchvision like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import functools from torchvision.transforms import v2 # subtract constant value from the image def subtract_const(src_image, const_val): return src_image - const_val ## subtract global mean channel background train_data_ch_avg = torch.tensor([[[0.4914]],[[0.4822]],[[0.4465]]]) # NOTE: train_data_ch_avg is obtained from the channel mean value calculation code print(train_data_ch_avg.size()) subtract_ch_avg = functools.partial(subtract_const, const_val = train_data_ch_avg) subtract_channel_mean_transform = v2.Lambda(subtract_ch_avg) Data Augmentation The VGG paper also employed various data augmentation techniques to prevent overfitting. Here\u0026rsquo;s how we implement them:\nRandom Horizontal Flip torchvision already includes a built-in transformation for randomly flipping images horizontally. Therefore, we can simply utilize this built-in transformation for horizontal flips.\n1 2 3 from torchvision.transforms import v2 rand_hflip_transform = v2.RandomHorizontalFlip(0.5) In the VGG paper, they utilized both the original image and its horizontally flipped counterpart to predict classification results. They then averaged these results to obtain the final classification. Consequently, we can implement the validation process as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # validate model in one epoch and return the top k-th result def validate_one_epoch_topk_aug( model, validate_loader, loss_func, transforms, device, top_k = 1 ): tot_loss = 0.0 avg_loss = 0.0 tot_nof_batch = len(validate_loader) correct_samples = 0 tot_samples = len(validate_loader.dataset) nof_transforms = len(transforms) model.eval() with torch.no_grad(): for i_batch, data in enumerate(validate_loader): inputs, labels = data inputs = inputs.to(device) labels = labels.to(device) group_outputs = [None for _ in range(nof_transforms)] group_loss = [None for _ in range(nof_transforms)] for i_trans in range(nof_transforms): cur_transform = transforms[i_trans] cur_input = inputs if cur_transform is not None: cur_input = cur_transform(inputs) cur_output = model(cur_input) cur_loss = loss_func(cur_output, labels) group_outputs[i_trans] = cur_output group_loss[i_trans] = cur_loss outputs = torch.mean(torch.stack(group_outputs, dim = 0), dim = 0) loss = torch.mean(torch.stack(group_loss, dim = 0), dim = 0) tot_loss += loss.item() # NOTE: we will define batch_in_top_k() later # NOTE: batch_in_top_k() return a mask array indicate if label in the top k result correct_samples += (batch_in_top_k(outputs, labels, top_k)).type(torch.float).sum().item() avg_loss = tot_loss/tot_nof_batch correct_rate = correct_samples/tot_samples print(f\u0026#34;Validate: top{top_k} Accuracy: {(100*correct_rate):\u0026gt;0.2f}%, Avg loss: {avg_loss:\u0026gt;8f}\u0026#34;) return (avg_loss, correct_rate) ## demo training validation loop validate_transforms = [None, torchvision.transforms.functional.hflip] for i_epoch in range(nof_epochs): print(f\u0026#34; ------ Epoch {i_epoch} ------ \u0026#34;) train_one_epoch(model, train_dataloader, loss_func, optimizer, device) validate_one_epoch_topk_aug(model, validate_dataloader, loss_func, validate_transforms, device, top_k) Random Color Shift In VGG, another augmentation technique involved adjusting the RGB values of training images by a random combination of the principal component analysis (PCA) eigenvectors derived from the RGB values across all pixels of all images in the training set. For a detailed explanation, refer to section 4.1 Data Augmentation in the AlexNet paper.\nHere\u0026rsquo;s how the random color shift is implemented:\nBefore training begins, we go through the entire training set and gather all RGB values from each image. This data is used to create an \\(m \\times n\\) data matrix, where \\(n\\) represents the number of channels (3 for RGB images) and \\(m\\) represents the total number of pixels across all images in the training set \\(m = \\text{number of images} \\times \\text{image height} \\times \\text{image width}\\). We then calculate the covariance matrix of this data matrix. Next, we conduct principal component analysis (PCA) on the covariance matrix using singular value decomposition (SVD). The resulting \\(U\\) matrix contains columns representing the PCA eigenvectors, and the \\(S\\) matrix contains the corresponding eigenvalues. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ## PCA for covariance matrix of image channels across all the pixels # train_dataloader is the dataloader iterating through the entire training data set input_dataloader = train_dataloader nof_batchs = len(input_dataloader) ch_vecs = [None for _ in range(nof_batchs)] for i_batch, data in enumerate(input_dataloader): inputs, labels = data # swap channel and batch axis and flatten the dimension of (batch, image height, image width) ch_vecs[i_batch] = torch.flatten(torch.swapaxes(inputs, 0, 1), start_dim = 1, end_dim = -1) ch_vecs = torch.cat(ch_vecs, dim = -1) ch_cov = torch.cov(ch_vecs) ch_vecs = None U, S, Vh = torch.linalg.svd(ch_cov, full_matrices = True) ## Each column of U is a channel PCA eigenvector ## S contains the corresponding to eigenvectors print(\u0026#34;U:\u0026#34;) print(repr(U)) print(\u0026#34;S:\u0026#34;) print(S) print(\u0026#34;Vh:\u0026#34;) print(Vh) Note: In this implementation, all pixels are loaded into computer memory at the same time. For larger datasets, the code for calculating the covariance matrix may need enhancements to compute it without simultaneously loading all data into memory.\nDuring training, we create a randomized linear combination of PCA eigenvectors by adding up the product of each eigenvector with a randomized amplitude. This amplitude is computed by multiplying the corresponding eigenvalue by a random value drawn from a Gaussian distribution with a mean of 0 and a standard deviation of 0.1.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 import functools from torchvision.transforms import v2 # image channel radom PCA eigenvec addition agumentation def random_ch_shift_pca(src_image, pca_eigenvecs, pca_eigenvals, random_paras = None): norm_meam = 0 norm_std = 0.1 if isinstance(random_paras, dict): norm_meam = random_paras.get(\u0026#34;mean\u0026#34;, norm_meam) norm_std = random_paras.get(\u0026#34;std\u0026#34;, norm_std) nof_dims = len(src_image.size()) nof_channels = src_image.size(0) assert(pca_eigenvecs.size(0) == nof_channels) assert(len(pca_eigenvals.size()) == 1) assert(pca_eigenvals.size(0) == pca_eigenvecs.size(1)) norm_means = 0 * torch.ones(pca_eigenvals.size()) norm_stds = 0.1 * torch.ones(pca_eigenvals.size()) alphas = torch.normal(norm_means, norm_stds) scale_factors = (alphas * pca_eigenvals).view((-1,1)) ch_offset = torch.matmul(pca_eigenvecs, scale_factors) ch_offset = ch_offset.view((nof_channels,) + (1,) * (nof_dims - 1)) dst_image = src_image + ch_offset return dst_image ## random channel shifts # NOTE: trainset_pca_eigenvecs and trainset_pca_eigenvals are the U and S matrix obtained from above mentioned PCA analysis trainset_pca_eigenvecs = torch.tensor([[-0.5580, 0.7063, 0.4356], [-0.5775, 0.0464, -0.8151], [-0.5960, -0.7063, 0.3820]]) print(trainset_pca_eigenvecs.size()) trainset_pca_eigenvals = torch.tensor([0.1719, 0.0139, 0.0029]) print(trainset_pca_eigenvals.size()) random_ch_shift = functools.partial(random_ch_shift_pca, pca_eigenvecs = trainset_pca_eigenvecs, pca_eigenvals = trainset_pca_eigenvals, random_paras = {\u0026#34;mean\u0026#34;: 0, \u0026#34;std\u0026#34;: 0.1}, ) random_ch_shift_transform = v2.Lambda(random_ch_shift) Other Data Augmentations The VGG paper also employed additional augmentation techniques like random translations and random crops. However, since the CIFAR dataset\u0026rsquo;s image size is much smaller (32x32) compared to the ImageNet dataset (256x256), there isn\u0026rsquo;t much flexibility to utilize these techniques effectively.\nSummary of Data Transformations In summary, the data transformations for the training set, including preprocessing and all data augmentation techniques, can be implemented as follows:\n1 2 3 4 5 6 7 8 9 10 11 12 13 from torchvision.transforms import v2 # NOTE: subtract_ch_avg() is defined in the Data processing section # NOTE: random_ch_shift() is defined in the Random color shift section ## data transform for training train_data_transforms = v2.Compose([ v2.ToImage(), v2.ToDtype(torch.float32,scale = True), v2.Lambda(subtract_ch_avg), v2.RandomHorizontalFlip(0.5), v2.Lambda(random_ch_shift), ]) For the test/validation set, all we need to do is include the preprocessing step in the data transformations.\n1 2 3 4 5 6 7 8 9 10 from torchvision.transforms import v2 # NOTE: subtract_ch_avg() is defined in the Data processing section ## data transform for validation validate_data_transforms = v2.Compose([ v2.ToImage(), v2.ToDtype(torch.float32,scale = True), v2.Lambda(subtract_ch_avg), ]) Training and Validation Top k Accuracy (or Error) In the VGG paper, the main way they measured performance was using the top k error. In my version, I focused on calculating the top k accuracy instead. Top k accuracy shows how often the actual label is among the top k predictions made by the model with the highest confidence. On the other hand, top k error tells us how often the actual label is not included in the top k predictions.\nThe relationship between top k error and top k accuracy is simply connected by the following formula:\n$$ \\text{top k error} = 1 − \\text{top k accuracy} $$\nA higher top k accuracy and lower top k error indicate better model performance.\nDuring the validation (or test) process, the top k-th accuracy can be estimated by dividing the total number of valiation (or test) samples by the number of samples where the label is in the top k predictions.\n$$ \\text{top k accuracy} = \\frac{\\text{number of samples (label is in top k predictions)}}{\\text{total number of samples}} $$\nTherefore, top k accuracy can be calculated using the following code:\n1 2 3 4 5 6 7 # Evaluate if label is within top k prediction result for one batch of data def batch_in_top_k(outputs, labels, top_k = 1): sorted_outputs, sorted_idxs = torch.sort(outputs, dim = -1, descending = True) in_top_k = torch.full_like(labels, False) for cur_idx in range(top_k): in_top_k = torch.logical_or(sorted_idxs[:,cur_idx] == labels, in_top_k) return in_top_k In each batch, we organize the softmax layer results, which represent the confidences for each predicted category, in descending order. Then, we check if the ground truth label is among the top k predictions. This check result is stored in a boolean mask array, where \u0026rsquo;true\u0026rsquo; indicates the label is in the top k predictions, and \u0026lsquo;false\u0026rsquo; indicates it\u0026rsquo;s not. This boolean mask array holds the results for all samples within the batch. To find the total number of samples where the label is among the top k predictions, we simply sum the mask arrays from all batches.\nLoss Function, Regularization, and Optimizer VGG employs multinomial logistic regression as its loss function. For optimization, it utilizes mini-batch gradient descent with momentum and weight decay. In PyTorch, these can be implemented as follows:\n1 2 loss_func = torch.nn.CrossEntropyLoss() optimizer = torch.optim.SGD(model.parameters(), lr = 1E-2, momentum = 0.9, weight_decay= 5E-4) Additionally, dropout regularization has been incorporated into the model as another form of regularization as mentioned earlier in this post.\nLearning Rate Adjustment In the VGG paper, the authors initially train with a learning rate of 1E-2. Then, they reduce the learning rate by a factor of 10 when the validation set accuracy plateaus. This can be implemented using the ReduceLROnPlateau() function provided by PyTorch, like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( optimizer = optimizer, mode = \u0026#34;max\u0026#34;, factor = 0.1, patience = 10, threshold = 1E-3, min_lr = 0, ) # Demo training and validation loop for i_epoch in range(nof_epochs): print(f\u0026#34; ------ Epoch {i_epoch} ------ \u0026#34;) cur_lr = optimizer.param_groups[0][\u0026#39;lr\u0026#39;]; print(f\u0026#34;current lr = {cur_lr}\u0026#34;) cur_train_loss = train_one_epoch(model, train_dataloader, loss_func, optimizer, device) cur_validate_loss, cur_validate_accuracy = validate_one_epoch_topk_aug(model, validate_dataloader, loss_func, validate_transforms, device, top_k) scheduler.step(cur_validate_accuracy) print(\u0026#34;\\n\u0026#34;) NOTE: The description of the ReduceLROnPlateau() function in the PyTorch documentation can be confusing. I found that reading the source code of the ReduceLROnPlateau() definition provides clearer understanding.\nTraining Deep Models Optimizing deep models from scratch with completely random initialization can be very challenging for the optimizer. It often leads to the learning process getting stuck for long periods.\nTo tackle this issue, the VGG authors first train a shallow model. Then, they use the learned parameters from this shallow model to initialize deeper ones.\nTransferring learned parameters between models in PyTorch is straightforward. It involves copying the learnable parameters state_dict (i.e. weights and biases) from corresponding layers between the two models. If you\u0026rsquo;re using the VGG model definition from this blog post, the example code looks like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 ## demo transfer model parameters input_image_width = 32 input_image_height = 32 # create model 1 model1_stacked_conv_list = [ [ {\u0026#34;nof_layers\u0026#34;: 1, \u0026#34;in_channels\u0026#34;: 3, \u0026#34;out_channels\u0026#34;: 64,}, ], [ {\u0026#34;nof_layers\u0026#34;: 1, \u0026#34;in_ckjhannels\u0026#34;: 64, \u0026#34;out_channels\u0026#34;: 128,}, ], ] conv_image_reduce_ratio = 2**len(model1_stacked_conv_list) conv_final_image_width = input_image_width//conv_image_reduce_ratio conv_final_image_height = input_image_height//conv_image_reduce_ratio model1_stacked_linear = [ { \u0026#34;nof_layers\u0026#34;: 1, \u0026#34;in_features\u0026#34;: conv_final_image_width * conv_final_image_height * 512, \u0026#34;out_features\u0026#34;: 512, \u0026#34;dropout_p\u0026#34;: 0.5 }, { \u0026#34;nof_layers\u0026#34;: 1, \u0026#34;out_features\u0026#34;: 10, \u0026#34;activation\u0026#34;: None } ] model1 = VGG.VGG( stacked_conv_descriptors = model1_stacked_conv_list, stacked_linear_descriptor = model1_stacked_linear, enable_debug = False, ) # create model 2 model2_stacked_conv_list = [ [ {\u0026#34;nof_layers\u0026#34;: 1, \u0026#34;in_channels\u0026#34;: 3, \u0026#34;out_channels\u0026#34;: 64,}, ], [ {\u0026#34;nof_layers\u0026#34;: 2, \u0026#34;in_ckjhannels\u0026#34;: 64, \u0026#34;out_channels\u0026#34;: 128,}, ], ] conv_image_reduce_ratio = 2**len(model2_stacked_conv_list) conv_final_image_width = input_image_width//conv_image_reduce_ratio conv_final_image_height = input_image_height//conv_image_reduce_ratio model2_stacked_linear = [ { \u0026#34;nof_layers\u0026#34;: 1, \u0026#34;in_features\u0026#34;: conv_final_image_width * conv_final_image_height * 512, \u0026#34;out_features\u0026#34;: 512, \u0026#34;dropout_p\u0026#34;: 0.5 }, { \u0026#34;nof_layers\u0026#34;: 1, \u0026#34;out_features\u0026#34;: 10, \u0026#34;activation\u0026#34;: None } ] model2 = VGG.VGG( stacked_conv_descriptors = model2_stacked_conv_list, stacked_linear_descriptor = model2_stacked_linear, enable_debug = False, ) # transfer parameter of 1st convoluation layer from model 1 to model 2 model2.network[0].network[0].load_state_dict(model1.network[0].network[0].state_dict()) NOTE: We\u0026rsquo;ve organized the sequential layers of the VGG model and stacked them within the \u0026ldquo;network\u0026rdquo; attribute of the object. This means we can access each specific layer inside the network by indexing the \u0026ldquo;network\u0026rdquo; attribute.\nResults Given the large size of the ImageNet dataset and the extensive time required for training, we\u0026rsquo;ll opt for a smaller dataset, CIFAR10, to demonstrate training and validation more quickly.\nI\u0026rsquo;ve examined several models based on the VGG architecture, and I\u0026rsquo;ve listed some of them (model I, II, and III) below:\nModel Configuration I II III conv3-128 conv3-128 conv3-128 maxpool conv3-256 conv3-256 conv3-256 conv3-256 conv3-256 maxpool conv3-512 conv3-512 conv3-512 conv3-512 conv3-512 conv3-512 conv3-512 conv3-512 conv3-512 maxpool FC-1024 FC-1024 FC-1024 FC-1024 FC-1024 FC-10 FC-10 FC-10 soft-max After training these model variations, I computed the top 1 to top 5 accuracies using the CIFAR10 test dataset. Here\u0026rsquo;s a summary of the results:\nModel config. top-1 accuarcy(%) top-2 accuarcy(%) top-3 accuarcy(%) top-4 accuarcy(%) top-5 accuarcy(%) I 82.45 92.74 96.23 97.82 98.87 II 84.88 93.95 96.91 98.23 98.99 III 86.93 94.39 96.83 98.15 98.90 We can observe that the accuracy tends to improve as the depth of the models increases.\nConclusion In this blog post, we\u0026rsquo;ve covered the implementation, training, and evaluation of the VGG network in a step-by-step manner. The VGG model showcases the effectiveness of deep neural networks in tackling image classification tasks. Moreover, their methods for data augmentation, regularization, and training provide valuable insights and lessons for training deep neural networks.\nReference [1] Simonyan, K., \u0026amp; Zisserman, A. (2014). Very deep convolutional networks for Large-Scale image recognition. arXiv (Cornell University). https://doi.org/10.48550/arxiv.1409.1556\n[2] Krizhevsky, A., Sutskever, I., \u0026amp; Hinton, G. E. (2012). ImageNet Classification with Deep Convolutional Neural Networks. Neural Information Processing Systems, 25, 1097–1105. https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\n[3] Krizhevsky, A., Nair, V. and Hinton, G. (2014) The CIFAR-10 Dataset. https://www.cs.toronto.edu/~kriz/cifar.html\nCitation If you found this article helpful, please cite it as:\nZhong, Jian (May 2024). Building and Training VGG with PyTorch: A Step-by-Step Guide. Vision Tech Insights. https://jianzhongdev.github.io/VisionTechInsights/posts/implement_train_vgg_pytorch/.\nOr\n@article{zhong2024buildtrainVGGPyTorch, title = \u0026#34;Building and Training VGG with PyTorch: A Step-by-Step Guide\u0026#34;, author = \u0026#34;Zhong, Jian\u0026#34;, journal = \u0026#34;jianzhongdev.github.io\u0026#34;, year = \u0026#34;2024\u0026#34;, month = \u0026#34;May\u0026#34;, url = \u0026#34;https://jianzhongdev.github.io/VisionTechInsights/posts/implement_train_vgg_pytorch/\u0026#34; } ","permalink":"http://localhost:1313/posts/implement_train_vgg_pytorch/","summary":"The VGG (Visual Geometry Group) model is a type of convolutional neural network (CNN) outlined in the paper Very Deep Convolutional Networks for Large-Scale Image Recognition. It\u0026rsquo;s known for its use of small convolution filters and deep layers, which helped it achieve top-notch performance in tasks like image classification. By stacking multiple layers with small kernel sizes, VGG can capture a wide range of features from input images. Plus, adding more rectification layers makes its decision-making process sharper and more accurate.","title":"Building and Training VGG with PyTorch: A Step-by-Step Guide"},{"content":"Configuration files are commonly used to adjust settings in computer programs. I\u0026rsquo;m presently developing a configuration file parser for my high-speed data acquisition system using C++. Along the way, I\u0026rsquo;ve discovered some useful techniques involving C++ generics and inheritance that streamline coding. Therefore, I decided to document these tricks in the hope that they\u0026rsquo;ll be beneficial to others. You can find the ready-to-use source code for this configuration file parser in my GitHub repository. (URL: https://github.com/JianZhongDev/CppConfigFile.)\nConfiguration Files According to Wikipedia, configuration files are files used to set up the parameters and initial settings for computer programs. A configuration file parser is a piece of program that allows saving program settings to and loading them from configuration files. Configuration files are very handy when users need to provide certain configuration settings to the program before starting it. In my research, I\u0026rsquo;ve also discovered the convenience of having a configuration file parser to record the configuration settings of my experiments. This enables me to quickly switch between different software settings for various applications.\nRequirement Analysis For a data acquisition program, users often need to fine-tune settings to optimize performance for their specific needs. This includes things like timing delays, filtering coefficients, and switching between different data processing methods. These settings are stored as variables with various data types (like numbers, strings, and arrays) in the software. So, the configuration file parser has to handle a wide range of data types.\nWe also want the configuration file to be easily readable and editable by users, so it needs to be in a human-readable text format. This means the parser should be able to convert variables to strings and back again.\nPlus, it\u0026rsquo;d be great if users could add comments to the configuration file to keep track of changes.\nIn summary, here\u0026rsquo;s what the configuration file parser needs to do:\nStore multiple setting variables and their values. Handle values with different data types. Convert variables to strings, and update values from strings. Save settings to a text file that\u0026rsquo;s easy for humans to read. Update variable values from the text file. Process configuration files with comments. Data Structure and Algorithm Design Once we\u0026rsquo;ve nailed down the requirements, we can begin designing the data structures to meet them.\nGeneric Entry To handle the task of storing variables with different data types (requirement 2), we can develop our own custom class called GenericEntry. This class will enable us to access the data within it using the set() and get() methods for writing and reading data, respectively. Since different data types require different methods for reading and writing, we make these set() and get() methods virtual and require subclasses to implement them. The GenericEntry class also includes a type_name member and a get_typename() method to record the data type and verify data types.\nFor converting data to and from strings (requirement 3), considering that various data types require different approaches for this conversion, the GenericEntry class provides write_val_string() and read_val_string() methods. These methods facilitate converting the data value to a string and vice versa.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // Base type of generic entry class GenericEntry { protected: std::string type_name; public: //TODO: could potentially change the return type from void to int and return error flag //TODO: could potentially use type_index instead of hardcoded string as the type identifier GenericEntry() { // set up the type_name in the constructor this-\u0026gt;type_name = \u0026#34;generic_entry\u0026#34;; } // Set value of the entry virtual void set() { //Override this method in subclass } // Get value of the entry virtual void get() { //Override this method in subclass } // Return string of the type name void get_typename(std::string* dst_string) { *dst_string = this-\u0026gt;type_name; } // Write the value of the entry into string virtual void write_val_string(std::string* dst_string) { //Override this method in subclass } // Read value of the entry from string virtual void read_val_string(const std::string\u0026amp; src_string) { //Override this method in subclass } }; Once we\u0026rsquo;ve set up the most basic entry type, we create a more specialized subclass named TypedEntry. Leveraging the generics template feature, we implement the set() and get() functions. However, because custom classes, iterable types, and primitive data types (like int and unsigned int) require unique approaches for converting their data to strings, we leave the write_val_string()and read_val_string() methods for future implementation in more specialized subclasses.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // Entry of generic type definition template\u0026lt;typename data_t\u0026gt; class TypedEntry : public GenericEntry { protected: data_t data; public: //Constructor without initial value TypedEntry() { this-\u0026gt;type_name = \u0026#34;typed_entry\u0026#34;; } //Constructor with initial value TypedEntry(data_t data) { this-\u0026gt;TypedEntry(); this-\u0026gt;data = data_t(data); } // Implemented set entry value method template\u0026lt;typename data_t\u0026gt; void set(const data_t\u0026amp; data) { this-\u0026gt;data = data_t(data); } // Implemented get entry value method template\u0026lt;typename data_t\u0026gt; void get(data_t* data_p) { *data_p = data_t(this-\u0026gt;data); } virtual void write_val_string(std::string* dst_string) { //Override this method in subclass } virtual void read_val_string(const std::string\u0026amp; src_string) { //Override this method in subclass } }; Primitive types (like int and unsigned int) have straightforward methods for converting between data and strings. We can implement their entry classes like this: For each specific primitive type, we simply inherit from the primitive type entry and specify the type name in the constructors.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // Entries with primitive type template\u0026lt;typename data_t\u0026gt; class PrimitiveTypeEntry : public TypedEntry\u0026lt;data_t\u0026gt; { // NOTE: Only need to define contructor giving type_name in the subclasses public: PrimitiveTypeEntry() { this-\u0026gt;type_name = \u0026#34;primitivetype_entry\u0026#34;; } PrimitiveTypeEntry(const data_t\u0026amp; data) { this-\u0026gt;PrimitiveTypeEntry(); this-\u0026gt;data = data_t(data); } virtual void write_val_string(std::string* dst_string) { *dst_string = std::to_string(this-\u0026gt;data); } virtual void read_val_string(const std::string\u0026amp; src_string) { if (std::is_fundamental\u0026lt;data_t\u0026gt;::value) { // validate the data type is primitive data type std::stringstream(src_string) \u0026gt;\u0026gt; this-\u0026gt;data; // use stringstream to convert value string to value } } }; // Entries with int type class IntEntry : public PrimitiveTypeEntry\u0026lt;int\u0026gt; { public: IntEntry(int data = 0) { this-\u0026gt;type_name = \u0026#34;int\u0026#34;; this-\u0026gt;data = data; } }; We can apply a similar approach to define types for vectors as well.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 // Vector class with primitive data type template\u0026lt;typename data_t\u0026gt; class VectorPrimitiveTypeEntry : public TypedEntry\u0026lt;std::vector\u0026lt;data_t\u0026gt;\u0026gt; { // NOTE: Only need to define contructor giving type_name in the subclasses protected: //NOTE: data string format: {val0, val1, val2} std::string str_dl = \u0026#34;,\u0026#34;; std::string str_enclosure[2] = { \u0026#34;{\u0026#34;, \u0026#34;}\u0026#34; }; public: VectorPrimitiveTypeEntry() { this-\u0026gt;type_name = \u0026#34;vector_primitivetype\u0026#34;; } VectorPrimitiveTypeEntry(const std::vector\u0026lt;data_t\u0026gt;\u0026amp; data) { this-\u0026gt;VectorPrimitiveTypeEntry(); this-\u0026gt;data = std::vector\u0026lt;data_t\u0026gt;(data); } virtual void write_val_string(std::string* dst_string) { std::stringstream result_strstream; unsigned data_len = this-\u0026gt;data.size(); unsigned count = 0; // iterate through data vector result_strstream \u0026lt;\u0026lt; this-\u0026gt;str_enclosure[0]; for (auto itr = this-\u0026gt;data.begin(); itr != this-\u0026gt;data.end(); ++itr) { result_strstream \u0026lt;\u0026lt; std::to_string(*itr); count++; if (count \u0026lt; data_len) result_strstream \u0026lt;\u0026lt; this-\u0026gt;str_dl; } result_strstream \u0026lt;\u0026lt; this-\u0026gt;str_enclosure[1]; *dst_string = result_strstream.str(); } virtual void read_val_string(const std::string\u0026amp; src_string) { // remove \u0026#39;{\u0026#39;, \u0026#39;}\u0026#39;, and \u0026#39;_\u0026#39; std::string tmp_str = helper_extract_string_between_enclosure(src_string, str_enclosure[0], str_enclosure[1]); tmp_str = helper_clean_tailheadchars_string(tmp_str, std::unordered_set\u0026lt;char\u0026gt;{\u0026#39; \u0026#39;}); // extract value string for each element std::vector\u0026lt;std::string\u0026gt; val_strs = helper_split_string_with_delimiter(tmp_str, this-\u0026gt;str_dl); if (std::is_fundamental\u0026lt;data_t\u0026gt;::value) { // validate data type // iterate through value strings for each element this-\u0026gt;data.clear(); for (auto itr = val_strs.begin(); itr != val_strs.end(); ++itr) { data_t tmp_val; std::stringstream(*itr) \u0026gt;\u0026gt; tmp_val; this-\u0026gt;data.push_back(tmp_val); } } } }; // Entry with float vector class VectorFloatEntry : public VectorPrimitiveTypeEntry\u0026lt;float\u0026gt; { public: VectorFloatEntry(const std::vector\u0026lt;float\u0026gt;\u0026amp; data = { 0.0 }) { this-\u0026gt;type_name = \u0026#34;vector_float\u0026#34;; this-\u0026gt;data = std::vector\u0026lt;float\u0026gt;(data); } }; Since a string is a more specialized class-based data type, we need to define its entry separately.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // Entries with string type class StringEntry : public TypedEntry\u0026lt;std::string\u0026gt; { protected: // NOTE: value string format: \u0026#34;value_string\u0026#34; std::string str_enclosure[2] = { \u0026#34;\\\u0026#34;\u0026#34;, \u0026#34;\\\u0026#34;\u0026#34; }; public: StringEntry(const std::string\u0026amp; data = \u0026#34;\u0026#34;) { this-\u0026gt;type_name = \u0026#34;string\u0026#34;; this-\u0026gt;data = data; } virtual void write_val_string(std::string* dst_string) { // Add \u0026#34; \u0026#34; to string *dst_string = str_enclosure[0] + std::string(this-\u0026gt;data) + str_enclosure[1]; } virtual void read_val_string(const std::string\u0026amp; src_string) { // Extract string between \u0026#34; \u0026#34; std::string tmp_str = helper_extract_string_between_enclosure(src_string, str_enclosure[0], str_enclosure[1]); this-\u0026gt;data = std::string(tmp_str); } }; Generic Hashmap Once we\u0026rsquo;ve got our generic entry class ready, we can tackle the task of storing data for multiple settings variables (requirement 1). We can achieve this by using a hash map (std::unordered_map), where we map the name of each setting variable to the entry storing its value. One important thing to remember is that when defining the hashmap, the value should be declared as a pointer to the base class. This prevents any issues where a subclass might get casted into the base class when adding it to the hashmap.\n1 2 typedef std::unordered_map\u0026lt;std::string, GenericEntry*\u0026gt; GenHashMap; GenHashMap test_genhashmap; With this generic hashmap setup, adding setting variables and entries is straightforward:\n1 2 // initialize generic hash map test_genhashmap[\u0026#34;int_val\u0026#34;] = new IntEntry(1); Converting the entry to and from a string is as simple as this:\n1 2 3 4 5 // update entry with string test_map[\u0026#34;int_val\u0026#34;]-\u0026gt;read_val_string(\u0026#34;-1\u0026#34;); // convert entry value into string std::string tmp_valstr; test_map[\u0026#34;int_val\u0026#34;]-\u0026gt;write_val_string(\u0026amp;tmp_valstr); After casting the entry to its subclass, we can easily set and retrieve values within the entry.\n1 2 3 4 5 // set value of entry ((IntEntry*)test_genhashmap[\u0026#34;int_val\u0026#34;])-\u0026gt;set(-1); // get value from entry int tmp_int; ((IntEntry*)test_genhashmap[\u0026#34;int_val\u0026#34;])-\u0026gt;get(\u0026amp;tmp_int); Furthermore, we can easily determine the type of the entry by calling the get_typename() method.\n1 2 3 // get type name string from entry std::string tmp_typename; test_map[\u0026#34;int_val\u0026#34;]-\u0026gt;get_typename(\u0026amp;tmp_typename); To simplify clearing the entire hashmap, I\u0026rsquo;ve created the clear_genhashmap() function, outlined below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 typedef int errflag_t; // delete all the elements in a generic hash map errflag_t clear_genhashmap( GenHashMap\u0026amp; gen_hashmap ) { // iterate through the hash map to release all the entries for (auto key_val_pair : gen_hashmap) { delete key_val_pair.second; } gen_hashmap.clear(); return 1; } Note: If maintaining the order of setting variables in the configuration file is crucial for your application, you can easily achieve this by switching the data type from std::unordered_map (hashmap) to std::ordered_map (tree-based map). Everything else in the code remains unchanged and can be used as is.\nSaving Configuration Files Since we\u0026rsquo;ve already implemented the string conversion function in the entries, saving the setting parameters to human-readable text files is straightforward. We simply need to iterate through the generic hashmap, saving the name (key), type, and value of each entry. Then, we add entry separators at the end of each entry and dump them into a text file. Additionally, I\u0026rsquo;ve included a header string to provide some helpful information in the configuration file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 // pack type name value string into one string std::string helper_pack_type_name_val_string( const std::string\u0026amp; type_string, const std::string\u0026amp; name_string, const std::string\u0026amp; val_string, const std::string\u0026amp; type_name_dl = \u0026#34; \u0026#34;, const std::string\u0026amp; name_val_dl = \u0026#34;=\u0026#34; ) { return type_string + type_name_dl + name_string + name_val_dl + val_string; } typedef int errflag_t; // save generic hash map entries to configuration text file errflag_t save_genhashmap_to_txt( const GenHashMap\u0026amp; gen_hashmap, const std::string\u0026amp; dst_file_path, std::ios_base::openmode dst_file_openmode = std::ios_base::out, const std::string\u0026amp; type_name_dl = \u0026#34; \u0026#34;, const std::string\u0026amp; name_val_dl = \u0026#34;=\u0026#34;, const std::string\u0026amp; entry_stop_str = \u0026#34;;\u0026#34;, const std::vector\u0026lt;std::string\u0026gt;\u0026amp; default_message_enclousre = {\u0026#34;/*\u0026#34;, \u0026#34;*/\u0026#34;}, const std::string\u0026amp; head_message = \u0026#34;\u0026#34; ) { errflag_t err_flag = 0; std::ofstream dst_file(dst_file_path, dst_file_openmode); if (dst_file.is_open()) { // save head message if given if (head_message.size() \u0026gt; 0) { dst_file \u0026lt;\u0026lt; default_message_enclousre[0] + head_message + default_message_enclousre[1] + \u0026#34;\\n\u0026#34;; } // iterate though hash map and save all entries for (const auto\u0026amp; key_val_pair : gen_hashmap) { std::string cur_name_str = key_val_pair.first; std::string cur_type_str; std::string cur_val_str; key_val_pair.second-\u0026gt;get_typename(\u0026amp;cur_type_str); key_val_pair.second-\u0026gt;write_val_string(\u0026amp;cur_val_str); // convert type name value to entry string std::string cur_entry_str = helper_pack_type_name_val_string( cur_type_str, cur_name_str, cur_val_str, type_name_dl, name_val_dl ); dst_file \u0026lt;\u0026lt; cur_entry_str + entry_stop_str + \u0026#34;\\n\u0026#34;; } dst_file.close(); // close file err_flag = 1; } else { //std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t Unable to open file. File path = \u0026#34; + dst_file_path \u0026lt;\u0026lt; std::endl; std::string err_msg = \u0026#34;ERR:\\t Unable to open file. File path = \u0026#34; + dst_file_path + \u0026#34;\\n\u0026#34;; std::cout \u0026lt;\u0026lt; err_msg; err_flag = -1; } return err_flag; } Loading Configuration Files Reading the setting information from the configuration file involves a bit more complexity. We need to handle comments in the file and avoid mistakenly reading separators within strings of entries with string type. These requirements are addressed by iterating through the entire configuration file string using two pointers. Here\u0026rsquo;s how it works:\nThe faster pointer moves ahead to mark the end of each candidate string while continuously checking the substring. The slower pointer sets the start position of each candidate string. Depending on the substring, the algorithm behaves as follows: If the substring matches the start separator of a string candidate to ignore, the faster pointer moves forward while ignoring all substrings until it finds the end separator of the ignore string candidate. If the substring matches the start separator of a comment string, the faster pointer continues moving forward while ignoring until it finds the end separator of the comment string candidate. The slower pointer ends up positioned after the end of the comment candidate string so that it\u0026rsquo;s not read in. If the substring matches the end separator of an entry string candidate, the substring between the slow and fast pointers is saved into the result vector. This indicates that we\u0026rsquo;ve found the string for the setting parameter entry. The entry string candidate undergoes some cleaning processes to remove any extra spaces and newline characters at both ends. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 // extract entry strings from complicated strings std::vector\u0026lt;std::string\u0026gt; helper_extract_entrystr( const std::string\u0026amp; src_string, const std::string\u0026amp; entry_stop_str = \u0026#34;;\u0026#34;, //string indicates the end of an entry string std::unordered_map\u0026lt;std::string, std::string\u0026gt; ignore_left_to_right_map = { {\u0026#34;//\u0026#34;, \u0026#34;\\n\u0026#34;}, {\u0026#34;/*\u0026#34;, \u0026#34;*/\u0026#34;} }, //string parts between \u0026#34;left\u0026#34; and \u0026#34;right\u0026#34; to ignore std::unordered_map\u0026lt;std::string, std::string\u0026gt; include_left_to_right_map = { {\u0026#34;\\\u0026#34;\u0026#34;, \u0026#34;\\\u0026#34;\u0026#34;} } //string parts between \u0026#34;left\u0026#34; and \u0026#34;right\u0026#34; to include ) { std::size_t slow_idx = 0; std::size_t fast_idx = 0; std::size_t srcstr_len = src_string.size(); std::size_t entry_stop_str_len = entry_stop_str.size(); // count string lengths in the left_to_right map keys std::unordered_set\u0026lt;std::size_t\u0026gt; ignore_left_lens; for (const auto\u0026amp; itr : ignore_left_to_right_map) { ignore_left_lens.insert(itr.first.size()); } // count string lengths in the left_to_right map keys std::unordered_set\u0026lt;std::size_t\u0026gt; include_left_lens; for (const auto\u0026amp; itr : include_left_to_right_map) { include_left_lens.insert(itr.first.size()); } // itrate through src_string to find all entry strings std::vector\u0026lt;std::string\u0026gt; entry_strs; while (fast_idx \u0026lt; srcstr_len) { // check string between \u0026#34;left\u0026#34; and \u0026#34;right\u0026#34; to include for (auto cur_left_len : include_left_lens) { if (fast_idx + cur_left_len \u0026gt; srcstr_len) continue; std::string cur_left_str = src_string.substr(fast_idx, cur_left_len); if (include_left_to_right_map.find(cur_left_str) != include_left_to_right_map.end()) { std::string cur_right_str = include_left_to_right_map[cur_left_str]; std::size_t cur_right_len = cur_right_str.size(); for (fast_idx += cur_left_len; fast_idx + cur_right_len \u0026lt; srcstr_len; ++fast_idx) { if (src_string.substr(fast_idx, cur_right_len) == cur_right_str) break; } fast_idx += cur_right_len; } } // check string between \u0026#34;left\u0026#34; and \u0026#34;right\u0026#34; to exclude for (auto cur_left_len : ignore_left_lens) { if (fast_idx + cur_left_len \u0026gt; srcstr_len) continue; std::string cur_left_str = src_string.substr(fast_idx, cur_left_len); if (ignore_left_to_right_map.find(cur_left_str) != ignore_left_to_right_map.end()) { std::string cur_right_str = ignore_left_to_right_map[cur_left_str]; std::size_t cur_right_len = cur_right_str.size(); for (fast_idx += cur_left_len; fast_idx + cur_right_len \u0026lt; srcstr_len; ++fast_idx) { if (src_string.substr(fast_idx, cur_right_len) == cur_right_str) break; } fast_idx += cur_right_len; slow_idx = fast_idx; } } if (fast_idx + entry_stop_str_len \u0026gt; srcstr_len) break; // reach the end of src_string // found complete entry string if (src_string.substr(fast_idx, entry_stop_str_len) == entry_stop_str) { entry_strs.push_back(src_string.substr(slow_idx, fast_idx - slow_idx)); slow_idx = fast_idx + 1; } ++fast_idx; } return entry_strs; } Once we have the entry strings, we\u0026rsquo;ll break them down into type, name, and value fields. Each string for these fields will be cleaned up, removing any extra spaces and newline characters at both ends. Then, we\u0026rsquo;ll check if the hashmap has a key with the specified name, using it to identify the entries. We\u0026rsquo;ll then examine the value of the entry and update it with the corresponding value string if the type matches.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 typedef int errflag_t; // update generic hash map entries according to configuration text file errflag_t update_genhashmap_from_txt( GenHashMap\u0026amp; gen_hashmap, const std::string\u0026amp; src_file_path, std::ios_base::openmode src_file_openmode = std::ios_base::in, const std::string\u0026amp; type_name_dl = \u0026#34; \u0026#34;, const std::string\u0026amp; name_val_dl = \u0026#34;=\u0026#34;, const std::string\u0026amp; entry_stop_str = \u0026#34;;\u0026#34;, const std::unordered_map\u0026lt;std::string, std::string\u0026gt;\u0026amp; ignore_left_to_right_map = {{\u0026#34;//\u0026#34;, \u0026#34;\\n\u0026#34;}, {\u0026#34;/*\u0026#34;, \u0026#34;*/\u0026#34;}}, const std::unordered_map\u0026lt;std::string, std::string\u0026gt;\u0026amp; include_left_to_right_map = {{\u0026#34;\\\u0026#34;\u0026#34;, \u0026#34;\\\u0026#34;\u0026#34;}}, const std::unordered_set\u0026lt;char\u0026gt;\u0026amp; rm_chars = {\u0026#39; \u0026#39;, \u0026#39;\\n\u0026#39;, \u0026#39;\\t\u0026#39;} ) { errflag_t err_flag = 0; std::ifstream src_file(src_file_path, src_file_openmode); if (src_file.is_open()) { std::string src_string( (std::istreambuf_iterator\u0026lt;char\u0026gt;(src_file)), std::istreambuf_iterator\u0026lt;char\u0026gt;() ); std::vector\u0026lt;std::string\u0026gt; entry_strings = helper_extract_entrystr( src_string, entry_stop_str, ignore_left_to_right_map, include_left_to_right_map ); for (auto\u0026amp; cur_entry_str : entry_strings) { std::string tmp_str; std::size_t tmp_str_len = 0; //clean up entry string tmp_str = helper_bothside_clean_chars( cur_entry_str, rm_chars ); // split entry string std::string type_string; std::string name_string; std::string value_string; helper_split_entrystr_into_type_name_val( tmp_str, type_name_dl, name_val_dl, \u0026amp;type_string, \u0026amp;name_string, \u0026amp;value_string ); // clean up name string name_string = helper_bothside_clean_chars( name_string, rm_chars ); // update entry if name exists if (gen_hashmap.find(name_string) != gen_hashmap.end()) { type_string = helper_bothside_clean_chars( type_string, rm_chars ); // update entry if type match std::string hp_typename; gen_hashmap[name_string]-\u0026gt;get_typename(\u0026amp;hp_typename); if (type_string == hp_typename) { value_string = helper_bothside_clean_chars( value_string, rm_chars ); gen_hashmap[name_string]-\u0026gt;read_val_string(value_string); } else { //std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\tType mismatch! \u0026#34; + type_string + \u0026#34; \u0026lt;--\u0026gt; \u0026#34; + hp_typename + \u0026#34;\\n\u0026#34;; std::string err_string = \u0026#34;ERR:\\tType mismatch! \u0026#34; + type_string + \u0026#34; \u0026lt;--\u0026gt; \u0026#34; + hp_typename + \u0026#34;\\n\u0026#34;; std::cout \u0026lt;\u0026lt; err_string; } } else { //std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\tName not found! \u0026#34; + name_string + \u0026#34;\\n\u0026#34;; std::string err_string = \u0026#34;ERR:\\tName not found! \u0026#34; + name_string + \u0026#34;\\n\u0026#34;; std::cout \u0026lt;\u0026lt; err_string; } } err_flag = 1; } else { //std::cout \u0026lt;\u0026lt; \u0026#34;ERR:\\t Unable to open file. File path = \u0026#34; + src_file_path \u0026lt;\u0026lt; std::endl; std::string err_string = \u0026#34;ERR:\\t Unable to open file. File path = \u0026#34; + src_file_path + \u0026#34;\\n\u0026#34;; std::cout \u0026lt;\u0026lt; err_string; err_flag = -1; } return err_flag; } Since we typically use the same separators and comment notations when writing and reading the configuration file, it makes sense to create a class to store these separators and comment notations for the functions responsible for saving and loading the configuration file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 typedef int errflag_t; // class for text IO of generic hash map class GenHashMapIOTxt { public: std::string type_name_dl = \u0026#34; \u0026#34;; std::string name_val_dl = \u0026#34;=\u0026#34;; std::string entry_stop_str = \u0026#34;;\u0026#34;; std::vector\u0026lt;std::string\u0026gt; default_message_enclousre = { \u0026#34;/*\u0026#34;, \u0026#34;*/\u0026#34; }; std::unordered_map\u0026lt;std::string, std::string\u0026gt; ignore_left_to_right_map = { {\u0026#34;//\u0026#34;, \u0026#34;\\n\u0026#34;}, {\u0026#34;/*\u0026#34;, \u0026#34;*/\u0026#34;} }; std::unordered_map\u0026lt;std::string, std::string\u0026gt; include_left_to_right_map = { {\u0026#34;\\\u0026#34;\u0026#34;, \u0026#34;\\\u0026#34;\u0026#34;} }; std::unordered_set\u0026lt;char\u0026gt; rm_chars = { \u0026#39; \u0026#39;, \u0026#39;\\n\u0026#39;, \u0026#39;\\t\u0026#39; }; // save generic hash map to file errflag_t save_to_file( const GenHashMap\u0026amp; gen_hashmap, const std::string\u0026amp; dst_file_path, std::ios_base::openmode dst_file_openmode = std::ios_base::out, const std::string\u0026amp; head_message = \u0026#34;\u0026#34; ) { return save_genhashmap_to_txt( gen_hashmap, dst_file_path, dst_file_openmode, this-\u0026gt;type_name_dl, //this-\u0026gt;name_val_dl, \u0026#34; \u0026#34; + this-\u0026gt;name_val_dl + \u0026#34; \u0026#34;, this-\u0026gt;entry_stop_str, this-\u0026gt;default_message_enclousre, head_message ); } // load generic hash map errflag_t update_from_file( GenHashMap\u0026amp; gen_hashmap, const std::string\u0026amp; src_file_path, std::ios_base::openmode src_file_openmode = std::ios_base::in ) { return update_genhashmap_from_txt( gen_hashmap, src_file_path, src_file_openmode, this-\u0026gt;type_name_dl, this-\u0026gt;name_val_dl, this-\u0026gt;entry_stop_str, this-\u0026gt;ignore_left_to_right_map, this-\u0026gt;include_left_to_right_map, this-\u0026gt;rm_chars ); } }; Unit Test Finally, we can quickly test the configuration file parser. In the following code, I\u0026rsquo;ve used an integer entry, a vector of floats entry, and a string entry as examples.\nFirst, we create the generic hashmap and add initial entries to it. Then, we save the generic hashmap to a text file. Next, we modify the values in the generic map. Finally, we load the values from the configuration file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 void main() { GenHashMap test_genhashmap; GenHashMapIOTxt test_io_txt; // initialize generic hash map test_genhashmap[\u0026#34;int_val\u0026#34;] = new IntEntry(1); test_genhashmap[\u0026#34;string_val\u0026#34;] = new StringEntry(\u0026#34;Welcome to Vision Tech Insights!\u0026#34;); test_genhashmap[\u0026#34;vector_float_val\u0026#34;] = new VectorFloatEntry({ 0.1, 0.2, 0.3, 0.4, 0.5 }); std::cout \u0026lt;\u0026lt; \u0026#34;====== Initialize gen hashmap ======\u0026#34; \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; std::endl; // print all the values in the generic hash map std::cout \u0026lt;\u0026lt; \u0026#34;--- genhashmap values START ---\u0026#34; \u0026lt;\u0026lt; std::endl; for (const auto\u0026amp; key_val_pair : test_genhashmap) { std::string cur_name_str = key_val_pair.first; std::string cur_type_str; std::string cur_val_str; key_val_pair.second-\u0026gt;get_typename(\u0026amp;cur_type_str); key_val_pair.second-\u0026gt;write_val_string(\u0026amp;cur_val_str); std::cout \u0026lt;\u0026lt; cur_type_str \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; cur_name_str \u0026lt;\u0026lt; \u0026#34; = \u0026#34; \u0026lt;\u0026lt; cur_val_str \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;--- genhashmap values END ---\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::endl; // save generic hash map into a text file std::cout \u0026lt;\u0026lt; \u0026#34;====== Save gen hashmap to text file ======\u0026#34; \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; std::endl; // save to txt configuration file test_io_txt.save_to_file( test_genhashmap, \u0026#34;test_config_file.txt\u0026#34;, std::ios_base::out, \u0026#34;This is the test configuration file for Vision Tech Insights blog.\u0026#34; ); // save generic hash map into a text file std::cout \u0026lt;\u0026lt; \u0026#34;====== Set values in gen hashmap ======\u0026#34; \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; std::endl; // try to change some of the values ((IntEntry*)test_genhashmap[\u0026#34;int_val\u0026#34;])-\u0026gt;set(-1); ((StringEntry*)test_genhashmap[\u0026#34;string_val\u0026#34;])-\u0026gt;set(std::string(\u0026#34;Hello world!\u0026#34;)); ((VectorFloatEntry*)test_genhashmap[\u0026#34;vector_float_val\u0026#34;])-\u0026gt;set(std::vector\u0026lt;float\u0026gt;{-0.1, -0.2, -0.3}); std::cout \u0026lt;\u0026lt; \u0026#34;--- genhashmap values START ---\u0026#34; \u0026lt;\u0026lt; std::endl; for (const auto\u0026amp; key_val_pair : test_genhashmap) { std::string cur_name_str = key_val_pair.first; std::string cur_type_str; std::string cur_val_str; key_val_pair.second-\u0026gt;get_typename(\u0026amp;cur_type_str); key_val_pair.second-\u0026gt;write_val_string(\u0026amp;cur_val_str); std::cout \u0026lt;\u0026lt; cur_type_str \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; cur_name_str \u0026lt;\u0026lt; \u0026#34; = \u0026#34; \u0026lt;\u0026lt; cur_val_str \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;--- genhashmap values END ---\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::endl; // try to get value from genhashmap std::cout \u0026lt;\u0026lt; \u0026#34;====== Get values from gen hashmap ======\u0026#34; \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; std::endl; int tmp_int; ((IntEntry*)test_genhashmap[\u0026#34;int_val\u0026#34;])-\u0026gt;get(\u0026amp;tmp_int); std::string tmp_string; ((StringEntry*)test_genhashmap[\u0026#34;string_val\u0026#34;])-\u0026gt;get(\u0026amp;tmp_string); std::vector\u0026lt;float\u0026gt; tmp_float_vec; ((VectorFloatEntry*)test_genhashmap[\u0026#34;vector_float_val\u0026#34;])-\u0026gt;get(\u0026amp;tmp_float_vec); std::cout \u0026lt;\u0026lt; \u0026#34;--- get values START ---\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;tmp_int = \u0026#34; \u0026lt;\u0026lt; tmp_int \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;tmp_float_vec = {\u0026#34;; for (int i_val = 0; i_val \u0026lt; tmp_float_vec.size(); i_val++) { std::cout \u0026lt;\u0026lt; tmp_float_vec[i_val]; if (i_val \u0026lt; tmp_float_vec.size() - 1) { std::cout \u0026lt;\u0026lt; \u0026#34;, \u0026#34;; } } std::cout \u0026lt;\u0026lt; \u0026#34;}\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;tmp_string = \u0026#34; \u0026lt;\u0026lt; tmp_string \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;--- get values END ---\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::endl; // load generic hash map from the text file std::cout \u0026lt;\u0026lt; \u0026#34;====== Load gen hashmap from text file ======\u0026#34; \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; std::endl; // update values according to txt configuration file test_io_txt.update_from_file( test_genhashmap, \u0026#34;test_config_file.txt\u0026#34;, std::ios_base::in ); std::cout \u0026lt;\u0026lt; \u0026#34;--- genhashmap values START ---\u0026#34; \u0026lt;\u0026lt; std::endl; for (const auto\u0026amp; key_val_pair : test_genhashmap) { std::string cur_name_str = key_val_pair.first; std::string cur_type_str; std::string cur_val_str; key_val_pair.second-\u0026gt;get_typename(\u0026amp;cur_type_str); key_val_pair.second-\u0026gt;write_val_string(\u0026amp;cur_val_str); std::cout \u0026lt;\u0026lt; cur_type_str \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; cur_name_str \u0026lt;\u0026lt; \u0026#34; = \u0026#34; \u0026lt;\u0026lt; cur_val_str \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;--- genhashmap values END ---\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::endl; // release generic entries and clear gen hashmap clear_genhashmap(test_genhashmap); } The resulting configuration file (\u0026ldquo;test_config_file.txt\u0026rdquo;) looks like this:\n/*This is the test configuration file for Vision Tech Insights blog.*/\rint int_val = 1;\rstring string_val = \u0026#34;Welcome to Vision Tech Insights!\u0026#34;;\rvector_float vector_float_val = {0.100000,0.200000,0.300000,0.400000,0.500000}; The output of the execution is as follows:\n====== Initialize gen hashmap ======\r--- genhashmap values START ---\rint int_val = 1\rstring string_val = \u0026#34;Welcome to Vision Tech Insights!\u0026#34;\rvector_float vector_float_val = {0.100000,0.200000,0.300000,0.400000,0.500000}\r--- genhashmap values END ---\r====== Save gen hashmap to text file ======\r====== Set values in gen hashmap ======\r--- genhashmap values START ---\rint int_val = -1\rstring string_val = \u0026#34;Hello world!\u0026#34;\rvector_float vector_float_val = {-0.100000,-0.200000,-0.300000}\r--- genhashmap values END ---\r====== Get values from gen hashmap ======\r--- get values START ---\rtmp_int = -1\rtmp_float_vec = {-0.1, -0.2, -0.3}\rtmp_string = Hello world!\r--- get values END ---\r====== Load gen hashmap from text file ======\r--- genhashmap values START ---\rint int_val = 1\rstring string_val = \u0026#34;Welcome to Vision Tech Insights!\u0026#34;\rvector_float vector_float_val = {0.100000,0.200000,0.300000,0.400000,0.500000}\r--- genhashmap values END --- Conclusion This post offers an example implementation of a configuration file parser using C++. We\u0026rsquo;ve developed a generic entry class to handle various data types and convert them into strings. Leveraging inheritance and generics in C++ allows us to reuse code blocks for different data types. Storing entries and their corresponding variable names in a hashmap enables us to manage multiple variables simultaneously. With a classic two-pointer-based string processing algorithm, we can save the hashmap to or load it from the configuration file.\nCitation If you found this article helpful, please cite it as:\nZhong, Jian (Apr 2024). Building a Configuration File Parser with C++. Vision Tech Insights. https://jianzhongdev.github.io/VisionTechInsights/posts/building_a_configuration_file_parser_with_cpp/.\nOr\n@article{zhong2024configfileparsercpp, title = \u0026#34;Building a Configuration File Parser with C++\u0026#34;, author = \u0026#34;Zhong, Jian\u0026#34;, journal = \u0026#34;jianzhongdev.github.io\u0026#34;, year = \u0026#34;2024\u0026#34;, month = \u0026#34;Apr\u0026#34;, url = \u0026#34;https://jianzhongdev.github.io/VisionTechInsights/posts/building_a_configuration_file_parser_with_cpp/.\u0026#34; } References [1] \u0026ldquo;Configuration file.\u0026rdquo; Wikipedia, The Free Encyclopedia. Wikimedia Foundation, Inc. Retrieved April 21, 2024, from https://en.wikipedia.org/wiki/Configuration_file.\n","permalink":"http://localhost:1313/posts/building_a_configuration_file_parser_with_cpp/","summary":"Configuration files are commonly used to adjust settings in computer programs. I\u0026rsquo;m presently developing a configuration file parser for my high-speed data acquisition system using C++. Along the way, I\u0026rsquo;ve discovered some useful techniques involving C++ generics and inheritance that streamline coding. Therefore, I decided to document these tricks in the hope that they\u0026rsquo;ll be beneficial to others. You can find the ready-to-use source code for this configuration file parser in my GitHub repository.","title":"Building a Configuration File Parser with C++"},{"content":"It\u0026rsquo;s really helpful to do some basic math to understand how well an imaging system works when you\u0026rsquo;re designing or improving it. Most of the time, a very basic model of the system can provide a ton of useful information. Therefore, I would like to share an example of how we can crunch some numbers to understand the signal and noise in a two-photon fluorescence microscope (2PFM). In the end, I will also provide a practical demo of how this math can help us make the system work better.\nIntroduction to Two-Photon Microscopy As shown in the cover image of this post, two-photon fluorescence microscopes work by scanning laser beams across a sample and capturing the fluorescent light emitted at each spot. Typically, they use scanning mirrors like galvo mirrors to move the laser beams around. At each scan location, laser beam reflected by the scanning mirrors is relayed to the objective lens using a tube lens and a scan lens. The objective lens then focuses the laser beam into the sample. Afterward, the fluorescence emitted from the sample is gathered by the same objective lens, redirected by a dichroic mirror (which transmits the excitation light while reflects the fluorescence), and finally gathered by some collection optics before being detected by a photodetector (usually a photomultiplier tube (PMT)).\nTwo photon fluorescence microscopes utilize two-photon excitation phenomenon to make fluorophores in samples light up. This happens when the molecules absorb two photons of light at the same time. Because of its low possibility, two photon excitation only occurs in the focal point inside the sample, where the laser beam is most intense (the density of the excitation photons reaches a maximum). To increase the efficiency of two photon excitation and avoid damaging the sample, two photon microscopes send laser pulses with very short pulse width (~femtosecond) into the sample, instead of using a high power continuous-wave laser .\nModeling of the Imaging System summary of the imaging system modeling (image credit: Jian Zhong)\nAt the heart of the two-photon microscope is the two-photon excitation phenomenon. So, when we model these microscopes, we\u0026rsquo;ll follow the sequence of this process: excitation, two-photon absorption, fluorescence generation, and finally fluorescence signal detection. Since each scan location behaves the same way, we\u0026rsquo;ll zoom in on just one spot for our analysis. We\u0026rsquo;ll start by looking at how fluorescence is generated with a single pulse and a single fluorophore, and then we\u0026rsquo;ll generalize our analysis to include multiple laser pulses and all the fluorophores within the focal point.\nTo keep our analysis focused on the most crucial factors, I've used \"\\(\\backsimeq\\)\" notation to show when things are equal by a constant factor, where the constant factor does not depend on the variable explicitly listed on the right-hand-side of the equation. So where wherever we see equation like \\( z \\backsimeq x \\cdot y \\), it means \\( z = const \\cdot (x \\cdot y) \\), where the constant \\(const\\) doesn’t depend on \\(x\\) and \\(y\\). Excitation Process Firstly, let’s model the input laser pulses incident to the sample. For most of the two photon systems we can find out the following details about the laser pulses.\nAverage power ( \\(P_{avg}\\) ): We can measure this by putting a power meter after the objective lens.\nRepetition rate ( \\(f_{PulseRR}\\) ): The laser specs usually tell us this, or we can measure it with an oscilloscope and a fast photo-diode.\nExcitation wavelength ( \\(\\lambda_{ext}\\) ): This is also in the laser specs, or we can measure it with a spectrometer.\nPulse width ( \\(\\tau_{PW}\\) ): We can measure this with an auto-correlator, or estimate it using the laser specs and the dispersion specs of the optics in the system.\nLaser pulses can have different shapes over time, but for our initial estimation, a simple rectangular shape is usually good enough. So, that\u0026rsquo;s what we\u0026rsquo;ll use in our analysis.\nWith these information, we can first calculate the instantaneous energy within a single laser pulse ( \\(E_{Pulse}\\) ) as follows:\n$$ E_{Pulse} = \\frac{P_{avg}}{f_{PulseRR}} $$\n( The trick to understand this formula is not difficult: the total energy during a certain duration \\(\\Delta t\\) is \\(P_{avg} \\cdot \\Delta t\\), and the number of pulses during this dulation is \\(f_{PulseRR} \\cdot \\Delta t\\) so the enery inside each pulse is simply the total energy divided by the number of pulses \\(E_{Pulse} = \\frac{P_{avg} \\cdot \\Delta t}{f_{PulseRR} \\cdot \\Delta t} = \\frac{P_{avg}}{f_{PulseRR}} \\) )\nConsidering that we modeled the laser pulse as a rectangular temporal profile, the instantaneous laser power within the duration of the laser pulse ( \\(P_{ins}\\) ) is as follows:\n$$ P_{ins} = \\frac{E_{Pulse}}{\\tau_{PW}} $$\nFurther analysis of the excitation process requires the knowledge of the excitation focus volume ( \\(V_{focus}\\) ). We can figure this out by measuring the Point Spread Function (PSF). Or, we can estimate it by modeling the excitation focus volume as a cylinder with a certain base area ( \\(A_{focus}\\) ) and height ( \\(d_{focus}\\) ), where the base area and height can be estimated using the lateral and axial resolution of the system respectively.\nFor conventional two photon microscopes, the lateral resolution ( \\(Res_{Lateral}\\) ) is given by:\n$$ Res_{Lateral} = 0.51 \\frac{\\lambda_{ext}}{\\sqrt{2} \\cdot NA} $$\nwhile the axial resolution ( \\(Res_{Axial}\\) ) is given by:\n$$ Res_{Axial} = 0.88 \\frac{\\lambda_{ext}}{\\sqrt{2} (\\ n - \\sqrt{n^2 - NA^2} )} $$\nWhere the \\(NA\\) is the numberical aperture of focused laser beam, \\(n\\) is the refractive index of the immesion medium.\nTypically, laser beam entering the objective lens fills its backpupil, so the \\(NA\\) of the focused laser beam is the same as the \\(NA\\) of the objective lens.\nFor water immersion objetive lenses, \\(n\\) is the refractive index of water ( \\(n = 1.33\\) ). For dry objective lenses, \\(n\\) is the refractive index of air ( \\(n = 1\\) ).\nWith the lateral and axial resolution of the two-photon microscope, the base area ( \\(A_{focus}\\) ) and height ( \\(d_{focus}\\) ) of the focus volume can be extimated as:\n$$ d_{focus} \\backsimeq Res_{Axial} $$\n$$ A_{focus} \\backsimeq \\pi \\cdot ( \\frac{Res_{Lateral}}{2} )^2 $$\nWith our simplied cylinder model for focus volume, focus volume ( \\(V_{focus}\\) ) can be calcualted as:\n$$ V_{focus} \\backsimeq A_{focus} \\cdot d_{focus} \\backsimeq \\pi \\cdot ( \\frac{Res_{Lateral}}{2} )^2 \\cdot Res_{Axial} $$\nThen, the instantaneous intensity of the excitation light during the duration of the laser pulse is as follows:\n$$ I_{ins} \\backsimeq \\frac{P_{ins}}{A_{focus}} = \\frac{E_{Pulse}}{A_{focus} \\cdot \\tau_{PW}} = \\frac{P_{avg}}{f_{PulseRR} \\cdot A_{focus} \\cdot \\tau_{PW}} $$\nTwo Photon Absorption and Fluorescence Generation Next, we\u0026rsquo;ll delve into modeling the two-photon absorption and fluorescence generation within the excitation volume. Typically, this volume contains numerous fluorophores. Initially, we\u0026rsquo;ll concentrate on describing how a single fluorophore interacts with a single laser pulse, then extend our findings to encompass all the fluorophore within the entire excitation volume interacting with a single laser pulse.\nDuring the two-photon absorption process, a fluorophore in its ground state absorbs two excitation photons and transitions to an excited state with a certain probability. This process is probabilistic, and its efficiency can be quantified using the two-photon transition rate ( \\(\\omega_{Transition}\\) ). This rate essentially tells us how many two-photon absorption events occur per unit time. In quantum mechanics, the two-photon transition rate is defined as follows:\n$$ \\omega_{Transition} = \\sigma_{2PCross} \\cdot ( I_{ins} )^2 \\backsimeq \\sigma_{2PCross} \\cdot (\\frac{P_{avg}}{f_{PulseRR} \\cdot A_{focus} \\cdot \\tau_{PW}})^2 $$\nHere, \\(\\sigma_{2PCross}\\) is the cross section of two photon absorption, which depends on the properties of the fluorophore.\nTwo photon absorption will only happen during the duration of the laser pulse, (during which the fluorophore encounters the excitation photons). With the transition rate, the following formula shows how many times this happens to one molecule during the entire laser pulse.\n$$ N_{Absorp} = \\omega_{Transition} \\cdot \\tau_{PW} $$ $$ \\backsimeq \\sigma_{2PCross} \\cdot (\\frac{P_{avg}}{f_{PulseRR} \\cdot A_{focus} \\cdot \\tau_{PW}})^2 \\cdot \\tau_{PW} $$ $$ = \\sigma_{2PCross} \\cdot P_{avg}^2 ( \\frac{1}{f_{PulseRR}} )^2 ( \\frac{1}{A_{focus}} )^2 \\frac{1}{\\tau_{PW}} $$\nOnce the fluorophore gets excited, it eventually returns to its original state and releases a fluorescence photon. This process happens with a certain probability. We use \\(\\eta_{Q}\\) to represent how efficiently this transition occurs from the excited state to emitting a fluorescence photon. It\u0026rsquo;s basically the conversion rate from absorbing two photons to emitting one fluorescence photon. The formula below tells us how many photons a single fluorophore emits during one laser pulse of excitation ( \\(N_{FP}\\) ).\n$$ N_{FP} = \\eta_{Q} \\cdot N_{Absorp} $$\n$$ \\backsimeq \\eta_{Q} \\cdot \\sigma_{2PCross} \\cdot P_{avg}^2 ( \\frac{1}{f_{PulseRR}} )^2 ( \\frac{1}{A_{focus}} )^2 \\frac{1}{\\tau_{PW}} $$\nNow, we finished the analysis of a single fluorophore interacting with a single laser pulse. Usually, the excitation volume contains more than one fluorophore. If we denote the density of the fluorophores as \\(\\rho_{fluor}\\) , then the total number of fluorophores within the excitation volume ( \\(N_{fluor}\\) ) can be expressed as:\n$$ N_{fluor} = \\rho_{fluor} \\cdot V_{focus} $$\nUsing the cylindrical model to represent the focused excitation volume, we can express the total number of fluorophores within that volume as follows:\n$$ N_{fluor} = \\rho_{fluor} \\cdot V_{focus} \\backsimeq \\rho_{fluor} \\cdot A_{focus} \\cdot d_{focus} $$\nAfter a single laser pulse hits the sample, the total number of fluorescence photons emitted from the focus volume ( \\(N_{totFP}\\) ) is just the result of multiplying the total number of fluorophores (within the focus volume) by the number of fluorescence photons emitted by each fluorophore.\n$$ N_{totFP} = N_{fluor} \\cdot N_{FP} $$ $$ \\backsimeq ( \\rho_{fluor} \\cdot A_{focus} \\cdot d_{focus} ) \\cdot ( \\eta_{Q} \\cdot \\sigma_{2PCross} \\cdot P_{avg}^2 ( \\frac{1}{f_{PulseRR}} )^2 ( \\frac{1}{A_{focus}} )^2 \\frac{1}{\\tau_{PW}} ) $$ $$ = \\rho_{fluor} \\cdot \\eta_{Q} \\cdot \\sigma_{2PCross} \\cdot P_{avg}^2 ( \\frac{1}{f_{PulseRR}} )^2 ( \\frac{1}{\\tau_{PW}} ) ( \\frac{1}{A_{focus}} ) \\cdot d_{focus} $$\nFluorescence Signal Detection The fluorescence photons will be collected by the objective lens, travel through the detection light path, and be detected by the photon detector. The photon detector converts them into a specific type of signal, usually electrical, which is easy to record and save. While the process of collecting them can be complex, we can simplify it by describing the efficiency of converting fluorescence photons to signals using a factor ( \\(\\eta_{collect}\\) ). This factor encompasses various elements like the numerical aperture of the objective lens, the transmission of the detection optics, and the conversion efficiency of the detectors. The signal is usually measured by the number of photons recorded, which we\u0026rsquo;ll call \u0026ldquo;signal photons\u0026rdquo; here. So, the total count of signal photons ( \\(N_{Signal}\\) ) generated by one laser pulse can be expressed as:\n$$ N_{Signal} = \\eta_{collect} \\cdot N_{totFP} $$\n$$ \\backsimeq \\eta_{collect} \\cdot \\rho_{fluor} \\cdot \\eta_{Q} \\cdot \\sigma_{2PCross} \\cdot P_{avg}^2 ( \\frac{1}{f_{PulseRR}} )^2 ( \\frac{1}{\\tau_{PW}} ) ( \\frac{1}{A_{focus}} ) \\cdot d_{focus} $$\nIntegration of Multiple Pulses and Signal-to-Noise Ratio Typically, in two-photon microscopes, the microscope stays at each pixel spot (or, scan location) for a specific amount of time (which is usually called dwell time). During this time, multiple laser pulses hit the sample, and all the fluorescence generated by these pulses are collected. So, the overall signal for each pixel spot (or, scan location) can be calculated like this:\n$$ N_{totSignal} = N_{pulse} \\cdot N_{Signal} $$ $$ \\backsimeq N_{pulse} \\cdot \\eta_{collect} \\cdot \\rho_{fluor} \\cdot \\eta_{Q} \\cdot \\sigma_{2PCross} \\cdot P_{avg}^2 ( \\frac{1}{f_{PulseRR}} )^2 ( \\frac{1}{\\tau_{PW}} ) ( \\frac{1}{A_{focus}} ) \\cdot d_{focus} $$\nWhere \\(N_{Pulse}\\) is the number of laser pulses that hit the sample at each scan location.\nThe distribution of signal photons usually follows a Poisson distribution. If we suppose that all other sources of noise in the system, like electrical noise, ambient light leaking in, or fluctuations in the laser pulse energy, are negligible, the signal to noise ratio (SNR) of each scan location can be written as:\n$$ SNR = \\sqrt{N_{totSignal}} $$\nSide Notes Usually, the specific characteristics of the fluorophores ( \\(\\rho_{fluor}\\) , \\(\\eta_{Q}\\) , and \\(\\sigma_{2PCross}\\) ) are difficult to be quantified. However, we can compare the signals from two fluorophores under the same conditions. By doing this, we can determine how much brighter one fluorophore is compared to another. Taking in the formula we derived above, for fluorophores A and B, if we image them with the same two photon microscope and exactly the same condition, we can have the following comparison result:\n$$ \\frac{ \\rho_{fluor_A} \\cdot \\eta_{Q_A} \\cdot \\sigma_{2PCross_A} }{ \\rho_{fluor_B} \\cdot \\eta_{Q_B} \\cdot \\sigma_{2PCross_B} } = \\frac{N_{totSignal_A}}{N_{totSignal_B}} $$\nExample Application As a practice, let’s explore how to double the signal-to-noise ratio (SNR) of a two photon microscope.\nTo improve the signal-to-noise ratio (SNR) of a two-photon imaging system by two times, we need to boost the signal by four times, according to the formula mentioned earlier. Here are some potential strategies we can consider:\nIncrease dwell time at each pixel by four times. This means letting the microscope linger longer at each pixel to gather more signal from the incident pulses. However, this might slow down the overall imaging process or reduce the number of pixels in the image, which could affect certain applications.\nCompress the pulse duration by four times. Adding a module for pulse compression or dispersion compensation optics in the system can achieve this. It helps in packing more energy into each pulse, potentially enhancing the signal.\nDouble the average power. While increasing power can boost signal strength, it must be done cautiously to avoid damaging the sample.\nEnhance detection efficiency by four times. This involves optimizing both the optical and electronic designs of the detection system to capture more of the fluorescence signal.\nThese methods aren\u0026rsquo;t mutually exclusive; we can combine several approaches to achieve the desired increase in SNR. However, it\u0026rsquo;s crucial to carefully evaluate the impact of each strategy on the overall system performance and the specific requirements of the application at hand.\nConclusion Understanding the imaging system in numbers is key for its design and optimization. The simplest math models and assumptions are a good start for our analysis, and usually reveal a lot about the system. Also, keep in mind the assumptions and simplifications we made during modeling. This way, we can easily come back to validate and refine your model later if needed.\nCitation If you found this article helpful, please cite it as:\nZhong, Jian (Apr 2024). Basic Math for Two Photon Fluorescence Microscopy. Vision Tech Insights. https://jianzhongdev.github.io/VisionTechInsights/posts/basic_math_for_two_photon_fluorescence_microscopy/.\nOr\n@article{zhong2024basicmath2PFM, title = \u0026#34;Basic Math for Two Photon Fluorescence Microscopy\u0026#34;, author = \u0026#34;Zhong, Jian\u0026#34;, journal = \u0026#34;jianzhongdev.github.io\u0026#34;, year = \u0026#34;2024\u0026#34;, month = \u0026#34;Apr\u0026#34;, url = \u0026#34;https://jianzhongdev.github.io/VisionTechInsights/posts/basic_math_for_two_photon_fluorescence_microscopy/\u0026#34; } ","permalink":"http://localhost:1313/posts/basic_math_for_two_photon_fluorescence_microscopy/","summary":"It\u0026rsquo;s really helpful to do some basic math to understand how well an imaging system works when you\u0026rsquo;re designing or improving it. Most of the time, a very basic model of the system can provide a ton of useful information. Therefore, I would like to share an example of how we can crunch some numbers to understand the signal and noise in a two-photon fluorescence microscope (2PFM). In the end, I will also provide a practical demo of how this math can help us make the system work better.","title":"Basic Math for Two Photon Fluorescence Microscopy"}]