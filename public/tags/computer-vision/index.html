<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Computer Vision | Vision Tech Insights</title>
<meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content="Jian Zhong"><link rel=canonical href=http://localhost:1313/tags/computer-vision/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5ff2630c4d1b3e25bc21f0ecd96681dbcf58219e741fa627857820b5485cb770.css integrity="sha256-X/JjDE0bPiW8IfDs2WaB289YIZ50H6YnhXggtUhct3A=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://localhost:1313/tags/computer-vision/index.xml><link rel=alternate hreflang=en href=http://localhost:1313/tags/computer-vision/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Computer Vision"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="http://localhost:1313/tags/computer-vision/"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary"><meta name=twitter:title content="Computer Vision"><meta name=twitter:description content="ExampleSite description"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Vision Tech Insights (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Vision Tech Insights</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/posts/ title=Posts><span>Posts</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/tags/>Tags</a></div><h1>Computer Vision
<a href=/tags/computer-vision/index.xml title=RSS aria-label=RSS><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="http://localhost:1313/images/autoencoders_with_pytorch_full_code_guide/AutoencoderCoverImage_hu096f3544ecf9e22ccd8866d640cdbb31_219241_360x0_resize_box_3.png 360w ,http://localhost:1313/images/autoencoders_with_pytorch_full_code_guide/AutoencoderCoverImage_hu096f3544ecf9e22ccd8866d640cdbb31_219241_480x0_resize_box_3.png 480w ,http://localhost:1313/images/autoencoders_with_pytorch_full_code_guide/AutoencoderCoverImage_hu096f3544ecf9e22ccd8866d640cdbb31_219241_720x0_resize_box_3.png 720w ,http://localhost:1313/images/autoencoders_with_pytorch_full_code_guide/AutoencoderCoverImage_hu096f3544ecf9e22ccd8866d640cdbb31_219241_1080x0_resize_box_3.png 1080w ,http://localhost:1313/images/autoencoders_with_pytorch_full_code_guide/AutoencoderCoverImage_hu096f3544ecf9e22ccd8866d640cdbb31_219241_1500x0_resize_box_3.png 1500w ,http://localhost:1313/images/autoencoders_with_pytorch_full_code_guide/AutoencoderCoverImage.png 3510w" sizes="(min-width: 768px) 720px, 100vw" src=http://localhost:1313/images/autoencoders_with_pytorch_full_code_guide/AutoencoderCoverImage.png alt="[cover image] Architecture of Autoencoder (image credit: Jian Zhong)" width=3510 height=1600></figure><header class=entry-header><h2 class=entry-hint-parent>Autoencoders with PyTorch: Full Code Guide</h2></header><div class=entry-content><p>An autoencoder is a type of artificial neural network that learns to create efficient codings, or representations, of unlabeled data, making it useful for unsupervised learning. Autoencoders can be used for tasks like reducing the number of dimensions in data, extracting important features, and removing noise. They’re also important for building semi-supervised learning models and generative models. The concept of autoencoders has inspired many advanced models.
In this blog post, we’ll start with a simple introduction to autoencoders....</p></div><footer class=entry-footer><span title='2024-06-23 00:00:00 +0000 UTC'>June 23, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;288 words&nbsp;·&nbsp;Jian Zhong</footer><a class=entry-link aria-label="post link to Autoencoders with PyTorch: Full Code Guide" href=http://localhost:1313/posts/autoencoders_with_pytorch_full_code_guide/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="http://localhost:1313/images/implement_train_VGG_PyTorch/VGGPyTorch_CoverImage_hu7178767123e027aa07b48b3dfea7116b_1234517_360x0_resize_box_3.png 360w ,http://localhost:1313/images/implement_train_VGG_PyTorch/VGGPyTorch_CoverImage_hu7178767123e027aa07b48b3dfea7116b_1234517_480x0_resize_box_3.png 480w ,http://localhost:1313/images/implement_train_VGG_PyTorch/VGGPyTorch_CoverImage_hu7178767123e027aa07b48b3dfea7116b_1234517_720x0_resize_box_3.png 720w ,http://localhost:1313/images/implement_train_VGG_PyTorch/VGGPyTorch_CoverImage_hu7178767123e027aa07b48b3dfea7116b_1234517_1080x0_resize_box_3.png 1080w ,http://localhost:1313/images/implement_train_VGG_PyTorch/VGGPyTorch_CoverImage_hu7178767123e027aa07b48b3dfea7116b_1234517_1500x0_resize_box_3.png 1500w ,http://localhost:1313/images/implement_train_VGG_PyTorch/VGGPyTorch_CoverImage.png 3200w" sizes="(min-width: 768px) 720px, 100vw" src=http://localhost:1313/images/implement_train_VGG_PyTorch/VGGPyTorch_CoverImage.png alt="[cover image] Architecture of VGG Model (image credit: Jian Zhong)" width=3200 height=1800></figure><header class=entry-header><h2 class=entry-hint-parent>Building and Training VGG with PyTorch: A Step-by-Step Guide</h2></header><div class=entry-content><p>The VGG (Visual Geometry Group) model is a type of convolutional neural network (CNN) outlined in the paper Very Deep Convolutional Networks for Large-Scale Image Recognition. It’s known for its use of small convolution filters and deep layers, which helped it achieve top-notch performance in tasks like image classification. By stacking multiple layers with small kernel sizes, VGG can capture a wide range of features from input images. Plus, adding more rectification layers makes its decision-making process sharper and more accurate....</p></div><footer class=entry-footer><span title='2024-05-13 00:00:00 +0000 UTC'>May 13, 2024</span>&nbsp;·&nbsp;20 min&nbsp;·&nbsp;4250 words&nbsp;·&nbsp;Jian Zhong</footer><a class=entry-link aria-label="post link to Building and Training VGG with PyTorch: A Step-by-Step Guide" href=http://localhost:1313/posts/implement_train_vgg_pytorch/></a></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Vision Tech Insights</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>